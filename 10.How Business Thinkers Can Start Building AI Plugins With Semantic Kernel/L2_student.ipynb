{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6824e7f-13cd-47da-9667-b6ca940ca3b8",
   "metadata": {},
   "source": [
    "# ğŸ§‘â€ğŸ³ Cooking up flavorful SWOTs with the kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e857b705-f74c-4c4a-a678-dd96cccd0776",
   "metadata": {},
   "source": [
    "## ğŸ”¥ Get a kernel ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f115a1a3-8ac0-4521-b953-ac20f69d5a97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting semantic_kernel\n",
      "  Downloading semantic_kernel-0.3.10.dev0-py3-none-any.whl (169 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m169.0/169.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting openai<0.28.0,>=0.27.0\n",
      "  Downloading openai-0.27.10-py3-none-any.whl (76 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex<2024.0.0,>=2023.6.3 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from semantic_kernel) (2023.6.3)\n",
      "Collecting openapi_core<0.19.0,>=0.18.0\n",
      "  Downloading openapi_core-0.18.0-py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydantic<2 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from semantic_kernel) (1.10.8)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.24.2 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from semantic_kernel) (1.24.3)\n",
      "Collecting prance<24.0.0.0,>=23.6.21.0\n",
      "  Downloading prance-23.6.21.0-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: python-dotenv==1.0.0 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from semantic_kernel) (1.0.0)\n",
      "Requirement already satisfied: aiofiles<24.0.0,>=23.1.0 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from semantic_kernel) (23.1.0)\n",
      "Requirement already satisfied: aiohttp in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from openai<0.28.0,>=0.27.0->semantic_kernel) (3.8.4)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from openai<0.28.0,>=0.27.0->semantic_kernel) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from openai<0.28.0,>=0.27.0->semantic_kernel) (4.65.0)\n",
      "Collecting jsonschema-spec<0.3.0,>=0.2.3\n",
      "  Downloading jsonschema_spec-0.2.4-py3-none-any.whl (14 kB)\n",
      "Collecting parse\n",
      "  Downloading parse-1.19.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting asgiref<4.0.0,>=3.6.0\n",
      "  Downloading asgiref-3.7.2-py3-none-any.whl (24 kB)\n",
      "Collecting openapi-schema-validator<0.7.0,>=0.6.0\n",
      "  Downloading openapi_schema_validator-0.6.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting jsonschema<5.0.0,>=4.18.0\n",
      "  Downloading jsonschema-4.19.0-py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m83.4/83.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting isodate\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting werkzeug\n",
      "  Downloading werkzeug-2.3.7-py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m242.2/242.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting more-itertools\n",
      "  Downloading more_itertools-10.1.0-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting openapi-spec-validator<0.7.0,>=0.6.0\n",
      "  Downloading openapi_spec_validator-0.6.0-py3-none-any.whl (32 kB)\n",
      "Collecting chardet>=3.0\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ruamel.yaml>=0.17.10\n",
      "  Downloading ruamel.yaml-0.17.32-py3-none-any.whl (112 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six~=1.15 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic_kernel) (1.16.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic_kernel) (23.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from pydantic<2->semantic_kernel) (4.6.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.19.0,>=0.18.0->semantic_kernel) (23.1.0)\n",
      "Collecting rpds-py>=0.7.1\n",
      "  Downloading rpds_py-0.10.0-cp310-cp310-macosx_11_0_arm64.whl (309 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m309.9/309.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting referencing>=0.28.4\n",
      "  Downloading referencing-0.30.2-py3-none-any.whl (25 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6\n",
      "  Using cached jsonschema_specifications-2023.7.1-py3-none-any.whl (17 kB)\n",
      "Collecting pathable<0.5.0,>=0.4.1\n",
      "  Downloading pathable-0.4.3-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from jsonschema-spec<0.3.0,>=0.2.3->openapi_core<0.19.0,>=0.18.0->semantic_kernel) (6.0)\n",
      "Requirement already satisfied: rfc3339-validator in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.19.0,>=0.18.0->semantic_kernel) (0.1.4)\n",
      "Collecting lazy-object-proxy<2.0.0,>=1.7.1\n",
      "  Downloading lazy-object-proxy-1.9.0.tar.gz (42 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->semantic_kernel) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->semantic_kernel) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->semantic_kernel) (2.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->semantic_kernel) (3.1.0)\n",
      "Collecting ruamel.yaml.clib>=0.2.7\n",
      "  Downloading ruamel.yaml.clib-0.2.7-cp310-cp310-macosx_12_0_arm64.whl (125 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m125.8/125.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: multidict<7.0,>=4.5 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic_kernel) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic_kernel) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic_kernel) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic_kernel) (1.9.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic_kernel) (4.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from werkzeug->openapi_core<0.19.0,>=0.18.0->semantic_kernel) (2.1.3)\n",
      "Building wheels for collected packages: lazy-object-proxy\n",
      "  Building wheel for lazy-object-proxy (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lazy-object-proxy: filename=lazy_object_proxy-1.9.0-cp310-cp310-macosx_11_0_arm64.whl size=21037 sha256=1191c32b64d8b7914ff3dd6c058117875d2984b5c83679804f54fc4c891ba966\n",
      "  Stored in directory: /Users/wlkim/Library/Caches/pip/wheels/db/8d/91/c1b8aa2f5f9b112963acfc68e8e0fb51f68c44c9a366006ae3\n",
      "Successfully built lazy-object-proxy\n",
      "Installing collected packages: parse, werkzeug, ruamel.yaml.clib, rpds-py, pathable, more-itertools, lazy-object-proxy, isodate, chardet, asgiref, ruamel.yaml, referencing, prance, openai, jsonschema-specifications, jsonschema-spec, jsonschema, openapi-schema-validator, openapi-spec-validator, openapi_core, semantic_kernel\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.28.0\n",
      "    Uninstalling openai-0.28.0:\n",
      "      Successfully uninstalled openai-0.28.0\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 4.17.3\n",
      "    Uninstalling jsonschema-4.17.3:\n",
      "      Successfully uninstalled jsonschema-4.17.3\n",
      "Successfully installed asgiref-3.7.2 chardet-5.2.0 isodate-0.6.1 jsonschema-4.19.0 jsonschema-spec-0.2.4 jsonschema-specifications-2023.7.1 lazy-object-proxy-1.9.0 more-itertools-10.1.0 openai-0.27.10 openapi-schema-validator-0.6.0 openapi-spec-validator-0.6.0 openapi_core-0.18.0 parse-1.19.1 pathable-0.4.3 prance-23.6.21.0 referencing-0.30.2 rpds-py-0.10.0 ruamel.yaml-0.17.32 ruamel.yaml.clib-0.2.7 semantic_kernel-0.3.10.dev0 werkzeug-2.3.7\n"
     ]
    }
   ],
   "source": [
    "!pip install semantic_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "219aaf60-94de-4156-80ed-d5d2a264fa39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A kernel is now ready.\n"
     ]
    }
   ],
   "source": [
    "import os  # ì¶”ê°€\n",
    "import semantic_kernel as sk\n",
    "\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, OpenAIChatCompletion\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = False\n",
    "\n",
    "if useAzureOpenAI:\n",
    "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"azureopenai\", AzureChatCompletion(deployment, endpoint, api_key))\n",
    "else:\n",
    "    # api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "    # kernel.add_text_completion_service(\"openai\", OpenAIChatCompletion(\"gpt-3.5-turbo-0301\", api_key, org_id))\n",
    "    api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    kernel.add_text_completion_service(\"openai\", OpenAIChatCompletion(\"gpt-3.5-turbo-0301\", api_key))\n",
    "\n",
    "print(\"A kernel is now ready.\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92569c51-b84c-4015-9e43-3daec1c7ab56",
   "metadata": {},
   "source": [
    "# Let's make a semantic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d15c5aa-43b6-4b6d-879c-6c2b212ba79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A semantic function for summarization has been registered.\n"
     ]
    }
   ],
   "source": [
    "sk_prompt = \"\"\"\n",
    "{{$input}}\n",
    "\n",
    "Summarize the content above in less than 140 characters in Korean.\n",
    "\"\"\"\n",
    "summary_function = kernel.create_semantic_function(prompt_template = sk_prompt,\n",
    "                                                    description=\"Summarizes the input to length of an old tweet.\",\n",
    "                                                    max_tokens=200,\n",
    "                                                    temperature=0.1,\n",
    "                                                    top_p=0.5)       \n",
    "print(\"A semantic function for summarization has been registered.\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f2328fa-b288-4ec6-a4e6-fedccd9126a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### âœ¨ í”¼ì ê°€ê²Œ ì£¼ì¸ì´ AIë¥¼ í™œìš©í•˜ë©´ ë§¤ì¶œì„ ë†’ì¼ ìˆ˜ ìˆë‹¤. AIëŠ” ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ íŒ¨í„´ì„ ì°¾ì•„ì£¼ê¸° ë•Œë¬¸ì´ë‹¤."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sk_input = \"\"\"\n",
    "Let me illustrate an example. Many weekends, I drive a few minutes from my house to a local pizza store to buy \n",
    "a slice of Hawaiian pizza from the gentleman that owns this pizza store. And his pizza is great, but he always \n",
    "has a lot of cold pizzas sitting around, and every weekend some different flavor of pizza is out of stock. \n",
    "But when I watch him operate his store, I get excited, because by selling pizza, he is generating data. \n",
    "And this is data that he can take advantage of if he had access to AI.\n",
    "\n",
    "AI systems are good at spotting patterns when given access to the right data, and perhaps an AI system could spot \n",
    "if Mediterranean pizzas sell really well on a Friday night, maybe it could suggest to him to make more of it on a \n",
    "Friday afternoon. Now you might say to me, \"Hey, Andrew, this is a small pizza store. What's the big deal?\" And I \n",
    "say, to the gentleman that owns this pizza store, something that could help him improve his revenues by a few \n",
    "thousand dollars a year, that will be a huge deal to him.\n",
    "\"\"\";\n",
    "# Text source: https://www.ted.com/talks/andrew_ng_how_ai_could_empower_any_business/transcript\n",
    "\n",
    "summary_result = await kernel.run_async(summary_function, input_str=sk_input)\n",
    "\n",
    "display(Markdown(\"### âœ¨ \" + str(summary_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d7c7dcc-ab52-4081-a96c-71b39535e2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### âœ¨ í”¼ì ê°€ê²Œ ì£¼ì¸ì´ ì¸ê³µì§€ëŠ¥ì„ í™œìš©í•˜ë©´ ë§¤ì¶œì„ ë†’ì¼ ìˆ˜ ìˆë‹¤. AIëŠ” ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ íŒ¨í„´ì„ ì°¾ì•„ ì¶”ì²œí•  ìˆ˜ ìˆë‹¤."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary_result = summary_function(sk_input)\n",
    "\n",
    "display(Markdown(\"### âœ¨ \" + str(summary_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b7e9b9-a497-4c85-a85e-1da40e4ff594",
   "metadata": {},
   "source": [
    "# Native functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0842b6e1-e3e7-4ec2-a36b-8cc56d4653cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is kind of not going to feel awesome but know this is a big deal\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.skill_definition import (\n",
    "    sk_function,\n",
    "    sk_function_context_parameter,\n",
    ")\n",
    "\n",
    "class ExoticLanguagePlugin:\n",
    "    def word_to_pig_latin(self, word):\n",
    "        vowels = \"AEIOUaeiou\"\n",
    "        if word[0] in vowels:\n",
    "            return word + \"way\"\n",
    "        for idx, letter in enumerate(word):\n",
    "            if letter in vowels:\n",
    "                break\n",
    "        else:\n",
    "            return word + \"ay\"\n",
    "        return word[idx:] + word[:idx] + \"ay\"\n",
    "    @sk_function(\n",
    "        description=\"Takes text and converts it to pig latin\",\n",
    "        name=\"pig_latin\",\n",
    "        input_description=\"The text to convert to pig latin\",\n",
    "    )\n",
    "    def pig_latin(self, sentence:str) -> str:\n",
    "        words = sentence.split()\n",
    "        pig_latin_words = []\n",
    "        for word in words:\n",
    "            pig_latin_words.append(self.word_to_pig_latin(word))\n",
    "        return ' '.join(pig_latin_words)\n",
    "\n",
    "exotic_language_plugin = kernel.import_skill(ExoticLanguagePlugin(), skill_name=\"exotic_language_plugin\")\n",
    "pig_latin_function = exotic_language_plugin[\"pig_latin\"]\n",
    "\n",
    "print(\"this is kind of not going to feel awesome but know this is a big deal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4357ad3-d6d0-44a7-a368-e9c10b913d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### âœ¨ í”¼ìay ê°€ê²Œay ì£¼ì¸ì´ay ì¸ê³µì§€ëŠ¥ì„ay í™œìš©í•˜ë©´ay ë§¤ì¶œì„ay ë†’ì¼ay ìˆ˜ay ìˆë‹¤.ay AIëŠ”way ë°ì´í„°ë¥¼ay í™œìš©í•˜ì—¬ay ë§¤ì¶œay íŒ¨í„´ì„ay íŒŒì•…í•˜ê³ ay ì¶”ì²œí• ay ìˆ˜ay ìˆë‹¤.ay"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_result = await kernel.run_async(summary_function, pig_latin_function, input_str=sk_input) \n",
    "\n",
    "display(Markdown(\"### âœ¨ \" + str(final_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bced2be-7dfa-458c-9916-108d3238494d",
   "metadata": {},
   "source": [
    "\n",
    "[![](./assets/andrew_ng.jpg)](assets/thepizzastore720.mp4)\n",
    "â€‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c092cb-3bf8-47c5-ae9f-c6ffa4424e5a",
   "metadata": {},
   "source": [
    "1. **Strengths**\n",
    "    - What unique recipes or ingredients does the pizza shop use?\n",
    "    - What are the skills and experience of the staff?\n",
    "    - Does the pizza shop have a strong reputation in the local area?\n",
    "    - Are there any unique features of the shop or its location that attract customers?\n",
    "2. **Weaknesses**\n",
    "    - What are the operational challenges of the pizza shop? (e.g., slow service, high staff turnover)\n",
    "    - Are there financial constraints that limit growth or improvements?\n",
    "    - Are there any gaps in the product offering?\n",
    "    - Are there customer complaints or negative reviews that need to be addressed?\n",
    "3. **Opportunities**\n",
    "    - Is there potential for new products or services (e.g., catering, delivery)?\n",
    "    - Are there under-served customer segments or market areas?\n",
    "    - Can new technologies or systems enhance the business operations?\n",
    "    - Are there partnerships or local events that can be leveraged for marketing?\n",
    "4. **Threats**\n",
    "    - Who are the major competitors and what are they offering?\n",
    "    - Are there potential negative impacts due to changes in the local area (e.g., construction, closure of nearby businesses)?\n",
    "    - Are there economic or industry trends that could impact the business negatively (e.g., increased ingredient costs)?\n",
    "    - Is there any risk due to changes in regulations or legislation (e.g., health and safety, employment)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6d410b-1dbd-418c-b57d-c3598bb6f6d8",
   "metadata": {},
   "source": [
    "| **Strengths**                                     | **Weaknesses**                                               |\n",
    "| --- | --- |\n",
    "| Unique garlic pizza recipe that wins top awards  | High staff turnover                                          |\n",
    "| Owner trained in Sicily at some of the best pizzerias                          | Floods in the area damaged the seating areas that are in need of repair  |\n",
    "| Strong local reputation                           | Absence of popular calzones from menu                        |\n",
    "| Prime location on university campus               | Negative reviews from younger demographic for lack of hip ingredients |\n",
    "\n",
    "Meanwhile there's money being left on the table (their opportunities) with calamities (their threats) waiting in the wings to possibly happen and may knock their pizza shop out cold.\n",
    "\n",
    "### ğŸ”– Opportunities and Threats\n",
    "\n",
    "| **Opportunities**                                 | **Threats**                                                  |\n",
    "| --- | ---|\n",
    "| Untapped catering potential                       | Rising competition from cheaper pizza businesses nearby |\n",
    "| Growing local tech startup community              | There's nearby street construction that will impact foot traffic |\n",
    "| Unexplored online presence and order capabilities | Rising cost of cheese                                        |\n",
    "| Upcoming annual food fair                         | No immediate local regulatory changes but it's election season |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7977e7f7-2100-4fdc-a348-c9fbe1ac3a82",
   "metadata": {},
   "source": [
    "## ğŸ¤· What does this have to do with LLMs and Semantic Kernel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fc96293-899c-4438-a891-7bccd0621630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made a kernel!\n"
     ]
    }
   ],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, OpenAIChatCompletion\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = False\n",
    "\n",
    "if useAzureOpenAI:\n",
    "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"azureopenai\", AzureChatCompletion(deployment, endpoint, api_key))\n",
    "else:\n",
    "    api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    kernel.add_text_completion_service(\"openai\", OpenAIChatCompletion(\"gpt-3.5-turbo-0301\", api_key))\n",
    "    # api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "    # kernel.add_text_completion_service(\"openai\", OpenAIChatCompletion(\"gpt-3.5-turbo-0301\", api_key, org_id))\n",
    "print(\"Made a kernel!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "193f0f62-913f-49cd-a592-5ffb33a2a96a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### âœ¨ Shift the SWOT interview questions to the world of software development\n",
       "ìœ„ì˜ ë¶„ì„ì„ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ë¹„ì¦ˆë‹ˆìŠ¤ ë„ë©”ì¸ìœ¼ë¡œ ë³€í™˜í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
       "\n",
       "1. **ê°•ì **\n",
       "    - ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì—ì„œ ê³ ìœ í•œ ê¸°ìˆ ì´ë‚˜ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ëŠ”ê°€?\n",
       "    - ê°œë°œìë“¤ì˜ ê¸°ìˆ ê³¼ ê²½í—˜ì´ ì¶©ë¶„í•œê°€?\n",
       "    - ë¡œì»¬ ì§€ì—­ì—ì„œ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ íšŒì‚¬ì˜ í‰íŒì´ ì¢‹ì€ê°€?\n",
       "    - íšŒì‚¬ë‚˜ ê°œë°œìì˜ ìœ„ì¹˜ë‚˜ íŠ¹ì§•ì´ ê³ ê°ì„ ëŒì–´ë“¤ì´ëŠ”ê°€?\n",
       "2. **ì•½ì **\n",
       "    - ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì—ì„œ ìš´ì˜ìƒì˜ ë¬¸ì œê°€ ìˆëŠ”ê°€? (ì˜ˆ: ëŠë¦° ì„œë¹„ìŠ¤, ë†’ì€ ì¸ë ¥ ì´ë™ë¥ )\n",
       "    - ì„±ì¥ì´ë‚˜ ê°œì„ ì„ ì œí•œí•˜ëŠ” ì¬ì •ì  ì œì•½ì´ ìˆëŠ”ê°€?\n",
       "    - ì œí’ˆ ì œê³µì—ì„œ ë¹ˆí‹ˆì´ ìˆëŠ”ê°€?\n",
       "    - ê³ ê° ë¶ˆë§Œì´ë‚˜ ë¶€ì •ì ì¸ ë¦¬ë·°ê°€ ìˆëŠ”ê°€?\n",
       "3. **ê¸°íšŒ**\n",
       "    - ìƒˆë¡œìš´ ì œí’ˆì´ë‚˜ ì„œë¹„ìŠ¤ (ì˜ˆ: ìƒˆë¡œìš´ ì•±, í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤)ë¥¼ ì¶œì‹œí•  ìˆ˜ ìˆëŠ” ê¸°íšŒê°€ ìˆëŠ”ê°€?\n",
       "    - ë¯¸ì²˜ ë‹¤ê°€ì˜¤ì§€ ì•Šì€ ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ë‚˜ ì‹œì¥ ì˜ì—­ì´ ìˆëŠ”ê°€?\n",
       "    - ìƒˆë¡œìš´ ê¸°ìˆ ì´ë‚˜ ì‹œìŠ¤í…œì´ ë¹„ì¦ˆë‹ˆìŠ¤ ìš´ì˜ì„ ê°œì„ í•  ìˆ˜ ìˆëŠ”ê°€?\n",
       "    - ë§ˆì¼€íŒ…ì— í™œìš©í•  ìˆ˜ ìˆëŠ” íŒŒíŠ¸ë„ˆì‹­ì´ë‚˜ ë¡œì»¬ ì´ë²¤íŠ¸ê°€ ìˆëŠ”ê°€?\n",
       "4. **ìœ„í˜‘**\n",
       "    - ì£¼ìš” ê²½ìŸ ì—…ì²´ê°€ ëˆ„êµ¬ì´ë©° ê·¸ë“¤ì´ ì œê³µí•˜ëŠ” ê²ƒì€ ë¬´ì—‡ì¸ê°€?\n",
       "    - ì§€ì—­ ë‚´ ë³€í™” (ì˜ˆ: ê±´ì„¤, ì¸ê·¼ ë¹„ì¦ˆë‹ˆìŠ¤ íì‡„)ë¡œ ì¸í•œ ë¶€ì •ì ì¸ ì˜í–¥ì´ ìˆëŠ”ê°€?\n",
       "    - ì‚°ì—… ê²½ì œë‚˜ ë™í–¥ì´ ë¹„ì¦ˆë‹ˆìŠ¤ì— ë¶€ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹  ê°€ëŠ¥ì„±ì´ ìˆëŠ”ê°€? (ì˜ˆ: ì¦ê°€í•˜ëŠ” ê°œë°œ ë¹„ìš©)\n",
       "    - ê·œì œë‚˜ ë²•ë¥ ì˜ ë³€í™”ë¡œ ì¸í•´ ìœ„í—˜ì´ ìˆëŠ”ê°€? (ì˜ˆ: ê°œì¸ì •ë³´ ë³´í˜¸, ì €ì‘ê¶Œ)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "swot_interview= \"\"\"\n",
    "1. **Strengths**\n",
    "    - What unique recipes or ingredients does the pizza shop use?\n",
    "    - What are the skills and experience of the staff?\n",
    "    - Does the pizza shop have a strong reputation in the local area?\n",
    "    - Are there any unique features of the shop or its location that attract customers?\n",
    "2. **Weaknesses**\n",
    "    - What are the operational challenges of the pizza shop? (e.g., slow service, high staff turnover)\n",
    "    - Are there financial constraints that limit growth or improvements?\n",
    "    - Are there any gaps in the product offering?\n",
    "    - Are there customer complaints or negative reviews that need to be addressed?\n",
    "3. **Opportunities**\n",
    "    - Is there potential for new products or services (e.g., catering, delivery)?\n",
    "    - Are there under-served customer segments or market areas?\n",
    "    - Can new technologies or systems enhance the business operations?\n",
    "    - Are there partnerships or local events that can be leveraged for marketing?\n",
    "4. **Threats**\n",
    "    - Who are the major competitors and what are they offering?\n",
    "    - Are there potential negative impacts due to changes in the local area (e.g., construction, closure of nearby businesses)?\n",
    "    - Are there economic or industry trends that could impact the business negatively (e.g., increased ingredient costs)?\n",
    "    - Is there any risk due to changes in regulations or legislation (e.g., health and safety, employment)?\"\"\"\n",
    "\n",
    "\n",
    "sk_prompt = \"\"\"\n",
    "{{$input}}\n",
    "\n",
    "Convert the analysis provided above to the business domain of {{$domain}}. Reply in Korean\n",
    "\"\"\"\n",
    "shift_domain_function = kernel.create_semantic_function(prompt_template=sk_prompt,\n",
    "                                                    description=\"Translate an idea to another domain.\",\n",
    "                                                    max_tokens=1000,\n",
    "                                                    temperature=0.1,\n",
    "                                                    top_p=0.5)\n",
    "my_context = kernel.create_new_context()\n",
    "\n",
    "my_context['input'] = swot_interview\n",
    "# my_context['domain'] = \"construction management\"\n",
    "my_context['domain'] = \"software development\"\n",
    "\n",
    "result = await kernel.run_async(shift_domain_function, input_context=my_context)\n",
    "\n",
    "display(Markdown(f\"### âœ¨ Shift the SWOT interview questions to the world of {my_context['domain']}\\n\"+ str(result)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2cc70ab-d0b3-4093-8440-ca6c380fea6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### âœ¨ Shift the SWOT interview questions to the world of software development at the level of cto\n",
       "ìœ„ì˜ ë¶„ì„ì„ CTOê°€ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ë¹„ì¦ˆë‹ˆìŠ¤ ë„ë©”ì¸ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì´ ì¬êµ¬ì„±í•©ë‹ˆë‹¤.\n",
       "\n",
       "1. **ê°•ì **\n",
       "    - ê¸°ìˆ ì  ìš°ìœ„: ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì—ì„œ ê³ ìœ í•œ ê¸°ìˆ ì´ë‚˜ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ëŠ”ê°€?\n",
       "    - ì¸ë ¥ ìš°ìˆ˜ì„±: ê°œë°œìë“¤ì˜ ê¸°ìˆ ê³¼ ê²½í—˜ì´ ì¶©ë¶„í•œê°€?\n",
       "    - í‰íŒ: ë¡œì»¬ ì§€ì—­ì—ì„œ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ íšŒì‚¬ì˜ í‰íŒì´ ì¢‹ì€ê°€?\n",
       "    - ë…íŠ¹í•œ ì œí’ˆ/ì„œë¹„ìŠ¤: ê³ ê°ì„ ìœ ì¹˜í•˜ëŠ” ë…íŠ¹í•œ ì œí’ˆì´ë‚˜ ì„œë¹„ìŠ¤ê°€ ìˆëŠ”ê°€?\n",
       "2. **ì•½ì **\n",
       "    - ìš´ì˜ìƒ ë¬¸ì œ: ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì—ì„œ ìš´ì˜ìƒì˜ ë¬¸ì œê°€ ìˆëŠ”ê°€? (ì˜ˆ: ëŠë¦° ì„œë¹„ìŠ¤, ë†’ì€ ì¸ë ¥ ìœ ë™ì„±)\n",
       "    - ì¬ì •ì  ì œì•½: ì„±ì¥ì´ë‚˜ ê°œì„ ì„ ì œí•œí•˜ëŠ” ì¬ì •ì  ì œì•½ì´ ìˆëŠ”ê°€?\n",
       "    - ì œí’ˆ ë¼ì¸ì—… ë¹ˆí‹ˆ: ì œí’ˆ ë¼ì¸ì—…ì— ë¹ˆí‹ˆì´ ìˆëŠ”ê°€?\n",
       "    - ê³ ê° ë¶ˆë§Œ/ë¶€ì •ì  ë¦¬ë·°: ê³ ê° ë¶ˆë§Œì´ë‚˜ ë¶€ì •ì ì¸ ë¦¬ë·°ê°€ ìˆëŠ”ê°€?\n",
       "3. **ê¸°íšŒ**\n",
       "    - ìƒˆë¡œìš´ ì œí’ˆ/ì„œë¹„ìŠ¤ ì¶œì‹œ: ìƒˆë¡œìš´ ì œí’ˆì´ë‚˜ ì„œë¹„ìŠ¤ (ì˜ˆ: ì»¨ì„¤íŒ…, í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤)ë¥¼ ì¶œì‹œí•  ìˆ˜ ìˆëŠ” ê¸°íšŒê°€ ìˆëŠ”ê°€?\n",
       "    - ë¯¸ì²˜ ë‹¤ê°€ì˜¤ì§€ ëª»í•œ ê³ ê° ì„¸ê·¸ë¨¼íŠ¸/ì‹œì¥ ì˜ì—­: ë¯¸ì²˜ ë‹¤ê°€ì˜¤ì§€ ëª»í•œ ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ë‚˜ ì‹œì¥ ì˜ì—­ì´ ìˆëŠ”ê°€?\n",
       "    - ê¸°ìˆ /ì‹œìŠ¤í…œ ê°œì„ : ìƒˆë¡œìš´ ê¸°ìˆ ì´ë‚˜ ì‹œìŠ¤í…œì´ ë¹„ì¦ˆë‹ˆìŠ¤ ìš´ì˜ì„ ê°œì„ í•  ìˆ˜ ìˆëŠ”ê°€?\n",
       "    - ë§ˆì¼€íŒ… íŒŒíŠ¸ë„ˆì‹­/ë¡œì»¬ ì´ë²¤íŠ¸: ë§ˆì¼€íŒ…ì— í™œìš©í•  ìˆ˜ ìˆëŠ” íŒŒíŠ¸ë„ˆì‹­ì´ë‚˜ ë¡œì»¬ ì´ë²¤íŠ¸ê°€ ìˆëŠ”ê°€?\n",
       "4. **ìœ„í˜‘**\n",
       "    - ê²½ìŸ ì—…ì²´: ì£¼ìš” ê²½ìŸ ì—…ì²´ê°€ ëˆ„êµ¬ì´ë©° ì–´ë–¤ ì œí’ˆì´ë‚˜ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ëŠ”ê°€?\n",
       "    - ì§€ì—­ ë³€í™”: ì§€ì—­ ë‚´ ë³€í™” (ì˜ˆ: ê±´ì„¤, ì¸ê·¼ ë¹„ì¦ˆë‹ˆìŠ¤ íì‡„)ë¡œ ì¸í•œ ë¶€ì •ì ì¸ ì˜í–¥ì´ ìˆëŠ”ê°€?\n",
       "    - ì‚°ì—… ê²½ì œ/íŠ¸ë Œë“œ ë³€í™”: ì‚°ì—… ê²½ì œë‚˜ íŠ¸ë Œë“œ ë³€í™”ë¡œ ì¸í•´ ë¹„ì¦ˆë‹ˆìŠ¤ì— ë¶€ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹  ê°€ëŠ¥ì„±ì´ ìˆëŠ”ê°€? (ì˜ˆ: ì¦ê°€í•˜ëŠ” ê°œë°œ ë¹„ìš©)\n",
       "    - ê·œì œ/ë²•ë¥  ë³€ê²½: ê·œì œë‚˜ ë²•ë¥  ë³€ê²½ìœ¼ë¡œ ì¸í•´ ìœ„í—˜ì´ ìˆëŠ”ê°€? (ì˜ˆ: ê°œì¸ì •ë³´ ë³´í˜¸, ì €ì‘ê¶Œ)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sk_prompt = \"\"\"\n",
    "{{$input}}\n",
    "\n",
    "Rewrite the text above to be understood by a {{$level}}. Rewrite in Korean.\n",
    "\"\"\"\n",
    "shift_reading_level_function = kernel.create_semantic_function(prompt_template=sk_prompt,\n",
    "                                                    description=\"Change the reading level of a given text.\",\n",
    "                                                    max_tokens=1000,\n",
    "                                                    temperature=0.1,\n",
    "                                                    top_p=0.5)\n",
    "\n",
    "my_context['input'] = swot_interview\n",
    "my_context['domain'] = \"software development\"\n",
    "my_context[\"level\"] = \"cto\"\n",
    "\n",
    "result = await kernel.run_async(shift_domain_function, shift_reading_level_function, input_context=my_context)\n",
    "\n",
    "display(Markdown(f\"### âœ¨ Shift the SWOT interview questions to the world of {my_context['domain']} at the level of {my_context['level']}\\n\"+ str(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0172ab77-cfa1-40a5-adb0-7dcf4c568d4b",
   "metadata": {},
   "source": [
    "## ğŸ”– Reminder: All âœ¨ generative responses result from having the model fill in the _____.\n",
    "\n",
    "![](./assets/completion.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d060b98f-8d3f-43c8-bb2a-f6f2529b358c",
   "metadata": {},
   "source": [
    "Reminder: Download your notebook to your computer if you wish to save your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472872c4-c2de-4bea-a03c-b939618fbe1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
