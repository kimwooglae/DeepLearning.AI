{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6824e7f-13cd-47da-9667-b6ca940ca3b8",
   "metadata": {},
   "source": [
    "# 🧑‍🍳 Cooking up flavorful SWOTs with the kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e857b705-f74c-4c4a-a678-dd96cccd0776",
   "metadata": {},
   "source": [
    "## 🔥 Get a kernel ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f115a1a3-8ac0-4521-b953-ac20f69d5a97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting semantic_kernel\n",
      "  Downloading semantic_kernel-0.3.10.dev0-py3-none-any.whl (169 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.0/169.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting openai<0.28.0,>=0.27.0\n",
      "  Downloading openai-0.27.10-py3-none-any.whl (76 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex<2024.0.0,>=2023.6.3 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from semantic_kernel) (2023.6.3)\n",
      "Collecting openapi_core<0.19.0,>=0.18.0\n",
      "  Downloading openapi_core-0.18.0-py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydantic<2 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from semantic_kernel) (1.10.8)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.24.2 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from semantic_kernel) (1.24.3)\n",
      "Collecting prance<24.0.0.0,>=23.6.21.0\n",
      "  Downloading prance-23.6.21.0-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: python-dotenv==1.0.0 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from semantic_kernel) (1.0.0)\n",
      "Requirement already satisfied: aiofiles<24.0.0,>=23.1.0 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from semantic_kernel) (23.1.0)\n",
      "Requirement already satisfied: aiohttp in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from openai<0.28.0,>=0.27.0->semantic_kernel) (3.8.4)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from openai<0.28.0,>=0.27.0->semantic_kernel) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from openai<0.28.0,>=0.27.0->semantic_kernel) (4.65.0)\n",
      "Collecting jsonschema-spec<0.3.0,>=0.2.3\n",
      "  Downloading jsonschema_spec-0.2.4-py3-none-any.whl (14 kB)\n",
      "Collecting parse\n",
      "  Downloading parse-1.19.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting asgiref<4.0.0,>=3.6.0\n",
      "  Downloading asgiref-3.7.2-py3-none-any.whl (24 kB)\n",
      "Collecting openapi-schema-validator<0.7.0,>=0.6.0\n",
      "  Downloading openapi_schema_validator-0.6.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting jsonschema<5.0.0,>=4.18.0\n",
      "  Downloading jsonschema-4.19.0-py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.4/83.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting isodate\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting werkzeug\n",
      "  Downloading werkzeug-2.3.7-py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.2/242.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting more-itertools\n",
      "  Downloading more_itertools-10.1.0-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting openapi-spec-validator<0.7.0,>=0.6.0\n",
      "  Downloading openapi_spec_validator-0.6.0-py3-none-any.whl (32 kB)\n",
      "Collecting chardet>=3.0\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ruamel.yaml>=0.17.10\n",
      "  Downloading ruamel.yaml-0.17.32-py3-none-any.whl (112 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six~=1.15 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic_kernel) (1.16.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic_kernel) (23.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from pydantic<2->semantic_kernel) (4.6.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.19.0,>=0.18.0->semantic_kernel) (23.1.0)\n",
      "Collecting rpds-py>=0.7.1\n",
      "  Downloading rpds_py-0.10.0-cp310-cp310-macosx_11_0_arm64.whl (309 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.9/309.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting referencing>=0.28.4\n",
      "  Downloading referencing-0.30.2-py3-none-any.whl (25 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6\n",
      "  Using cached jsonschema_specifications-2023.7.1-py3-none-any.whl (17 kB)\n",
      "Collecting pathable<0.5.0,>=0.4.1\n",
      "  Downloading pathable-0.4.3-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from jsonschema-spec<0.3.0,>=0.2.3->openapi_core<0.19.0,>=0.18.0->semantic_kernel) (6.0)\n",
      "Requirement already satisfied: rfc3339-validator in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.19.0,>=0.18.0->semantic_kernel) (0.1.4)\n",
      "Collecting lazy-object-proxy<2.0.0,>=1.7.1\n",
      "  Downloading lazy-object-proxy-1.9.0.tar.gz (42 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->semantic_kernel) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->semantic_kernel) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->semantic_kernel) (2.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->semantic_kernel) (3.1.0)\n",
      "Collecting ruamel.yaml.clib>=0.2.7\n",
      "  Downloading ruamel.yaml.clib-0.2.7-cp310-cp310-macosx_12_0_arm64.whl (125 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.8/125.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: multidict<7.0,>=4.5 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic_kernel) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic_kernel) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic_kernel) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic_kernel) (1.9.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic_kernel) (4.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/wlkim/anaconda3/envs/deeplearning-ai/lib/python3.10/site-packages (from werkzeug->openapi_core<0.19.0,>=0.18.0->semantic_kernel) (2.1.3)\n",
      "Building wheels for collected packages: lazy-object-proxy\n",
      "  Building wheel for lazy-object-proxy (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lazy-object-proxy: filename=lazy_object_proxy-1.9.0-cp310-cp310-macosx_11_0_arm64.whl size=21037 sha256=1191c32b64d8b7914ff3dd6c058117875d2984b5c83679804f54fc4c891ba966\n",
      "  Stored in directory: /Users/wlkim/Library/Caches/pip/wheels/db/8d/91/c1b8aa2f5f9b112963acfc68e8e0fb51f68c44c9a366006ae3\n",
      "Successfully built lazy-object-proxy\n",
      "Installing collected packages: parse, werkzeug, ruamel.yaml.clib, rpds-py, pathable, more-itertools, lazy-object-proxy, isodate, chardet, asgiref, ruamel.yaml, referencing, prance, openai, jsonschema-specifications, jsonschema-spec, jsonschema, openapi-schema-validator, openapi-spec-validator, openapi_core, semantic_kernel\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.28.0\n",
      "    Uninstalling openai-0.28.0:\n",
      "      Successfully uninstalled openai-0.28.0\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 4.17.3\n",
      "    Uninstalling jsonschema-4.17.3:\n",
      "      Successfully uninstalled jsonschema-4.17.3\n",
      "Successfully installed asgiref-3.7.2 chardet-5.2.0 isodate-0.6.1 jsonschema-4.19.0 jsonschema-spec-0.2.4 jsonschema-specifications-2023.7.1 lazy-object-proxy-1.9.0 more-itertools-10.1.0 openai-0.27.10 openapi-schema-validator-0.6.0 openapi-spec-validator-0.6.0 openapi_core-0.18.0 parse-1.19.1 pathable-0.4.3 prance-23.6.21.0 referencing-0.30.2 rpds-py-0.10.0 ruamel.yaml-0.17.32 ruamel.yaml.clib-0.2.7 semantic_kernel-0.3.10.dev0 werkzeug-2.3.7\n"
     ]
    }
   ],
   "source": [
    "!pip install semantic_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "219aaf60-94de-4156-80ed-d5d2a264fa39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A kernel is now ready.\n"
     ]
    }
   ],
   "source": [
    "import os  # 추가\n",
    "import semantic_kernel as sk\n",
    "\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, OpenAIChatCompletion\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = False\n",
    "\n",
    "if useAzureOpenAI:\n",
    "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"azureopenai\", AzureChatCompletion(deployment, endpoint, api_key))\n",
    "else:\n",
    "    # api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "    # kernel.add_text_completion_service(\"openai\", OpenAIChatCompletion(\"gpt-3.5-turbo-0301\", api_key, org_id))\n",
    "    api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    kernel.add_text_completion_service(\"openai\", OpenAIChatCompletion(\"gpt-3.5-turbo-0301\", api_key))\n",
    "\n",
    "print(\"A kernel is now ready.\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92569c51-b84c-4015-9e43-3daec1c7ab56",
   "metadata": {},
   "source": [
    "# Let's make a semantic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d15c5aa-43b6-4b6d-879c-6c2b212ba79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A semantic function for summarization has been registered.\n"
     ]
    }
   ],
   "source": [
    "sk_prompt = \"\"\"\n",
    "{{$input}}\n",
    "\n",
    "Summarize the content above in less than 140 characters in Korean.\n",
    "\"\"\"\n",
    "summary_function = kernel.create_semantic_function(prompt_template = sk_prompt,\n",
    "                                                    description=\"Summarizes the input to length of an old tweet.\",\n",
    "                                                    max_tokens=200,\n",
    "                                                    temperature=0.1,\n",
    "                                                    top_p=0.5)       \n",
    "print(\"A semantic function for summarization has been registered.\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f2328fa-b288-4ec6-a4e6-fedccd9126a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### ✨ 피자 가게 주인이 AI를 활용하면 매출을 높일 수 있다. AI는 데이터를 분석하여 패턴을 찾아주기 때문이다."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sk_input = \"\"\"\n",
    "Let me illustrate an example. Many weekends, I drive a few minutes from my house to a local pizza store to buy \n",
    "a slice of Hawaiian pizza from the gentleman that owns this pizza store. And his pizza is great, but he always \n",
    "has a lot of cold pizzas sitting around, and every weekend some different flavor of pizza is out of stock. \n",
    "But when I watch him operate his store, I get excited, because by selling pizza, he is generating data. \n",
    "And this is data that he can take advantage of if he had access to AI.\n",
    "\n",
    "AI systems are good at spotting patterns when given access to the right data, and perhaps an AI system could spot \n",
    "if Mediterranean pizzas sell really well on a Friday night, maybe it could suggest to him to make more of it on a \n",
    "Friday afternoon. Now you might say to me, \"Hey, Andrew, this is a small pizza store. What's the big deal?\" And I \n",
    "say, to the gentleman that owns this pizza store, something that could help him improve his revenues by a few \n",
    "thousand dollars a year, that will be a huge deal to him.\n",
    "\"\"\";\n",
    "# Text source: https://www.ted.com/talks/andrew_ng_how_ai_could_empower_any_business/transcript\n",
    "\n",
    "summary_result = await kernel.run_async(summary_function, input_str=sk_input)\n",
    "\n",
    "display(Markdown(\"### ✨ \" + str(summary_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d7c7dcc-ab52-4081-a96c-71b39535e2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### ✨ 피자 가게 주인이 인공지능을 활용하면 매출을 높일 수 있다. AI는 데이터를 분석하여 패턴을 찾아 추천할 수 있다."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary_result = summary_function(sk_input)\n",
    "\n",
    "display(Markdown(\"### ✨ \" + str(summary_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b7e9b9-a497-4c85-a85e-1da40e4ff594",
   "metadata": {},
   "source": [
    "# Native functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0842b6e1-e3e7-4ec2-a36b-8cc56d4653cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is kind of not going to feel awesome but know this is a big deal\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.skill_definition import (\n",
    "    sk_function,\n",
    "    sk_function_context_parameter,\n",
    ")\n",
    "\n",
    "class ExoticLanguagePlugin:\n",
    "    def word_to_pig_latin(self, word):\n",
    "        vowels = \"AEIOUaeiou\"\n",
    "        if word[0] in vowels:\n",
    "            return word + \"way\"\n",
    "        for idx, letter in enumerate(word):\n",
    "            if letter in vowels:\n",
    "                break\n",
    "        else:\n",
    "            return word + \"ay\"\n",
    "        return word[idx:] + word[:idx] + \"ay\"\n",
    "    @sk_function(\n",
    "        description=\"Takes text and converts it to pig latin\",\n",
    "        name=\"pig_latin\",\n",
    "        input_description=\"The text to convert to pig latin\",\n",
    "    )\n",
    "    def pig_latin(self, sentence:str) -> str:\n",
    "        words = sentence.split()\n",
    "        pig_latin_words = []\n",
    "        for word in words:\n",
    "            pig_latin_words.append(self.word_to_pig_latin(word))\n",
    "        return ' '.join(pig_latin_words)\n",
    "\n",
    "exotic_language_plugin = kernel.import_skill(ExoticLanguagePlugin(), skill_name=\"exotic_language_plugin\")\n",
    "pig_latin_function = exotic_language_plugin[\"pig_latin\"]\n",
    "\n",
    "print(\"this is kind of not going to feel awesome but know this is a big deal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4357ad3-d6d0-44a7-a368-e9c10b913d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### ✨ 피자ay 가게ay 주인이ay 인공지능을ay 활용하면ay 매출을ay 높일ay 수ay 있다.ay AI는way 데이터를ay 활용하여ay 매출ay 패턴을ay 파악하고ay 추천할ay 수ay 있다.ay"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_result = await kernel.run_async(summary_function, pig_latin_function, input_str=sk_input) \n",
    "\n",
    "display(Markdown(\"### ✨ \" + str(final_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bced2be-7dfa-458c-9916-108d3238494d",
   "metadata": {},
   "source": [
    "\n",
    "[![](./assets/andrew_ng.jpg)](assets/thepizzastore720.mp4)\n",
    "​"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c092cb-3bf8-47c5-ae9f-c6ffa4424e5a",
   "metadata": {},
   "source": [
    "1. **Strengths**\n",
    "    - What unique recipes or ingredients does the pizza shop use?\n",
    "    - What are the skills and experience of the staff?\n",
    "    - Does the pizza shop have a strong reputation in the local area?\n",
    "    - Are there any unique features of the shop or its location that attract customers?\n",
    "2. **Weaknesses**\n",
    "    - What are the operational challenges of the pizza shop? (e.g., slow service, high staff turnover)\n",
    "    - Are there financial constraints that limit growth or improvements?\n",
    "    - Are there any gaps in the product offering?\n",
    "    - Are there customer complaints or negative reviews that need to be addressed?\n",
    "3. **Opportunities**\n",
    "    - Is there potential for new products or services (e.g., catering, delivery)?\n",
    "    - Are there under-served customer segments or market areas?\n",
    "    - Can new technologies or systems enhance the business operations?\n",
    "    - Are there partnerships or local events that can be leveraged for marketing?\n",
    "4. **Threats**\n",
    "    - Who are the major competitors and what are they offering?\n",
    "    - Are there potential negative impacts due to changes in the local area (e.g., construction, closure of nearby businesses)?\n",
    "    - Are there economic or industry trends that could impact the business negatively (e.g., increased ingredient costs)?\n",
    "    - Is there any risk due to changes in regulations or legislation (e.g., health and safety, employment)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6d410b-1dbd-418c-b57d-c3598bb6f6d8",
   "metadata": {},
   "source": [
    "| **Strengths**                                     | **Weaknesses**                                               |\n",
    "| --- | --- |\n",
    "| Unique garlic pizza recipe that wins top awards  | High staff turnover                                          |\n",
    "| Owner trained in Sicily at some of the best pizzerias                          | Floods in the area damaged the seating areas that are in need of repair  |\n",
    "| Strong local reputation                           | Absence of popular calzones from menu                        |\n",
    "| Prime location on university campus               | Negative reviews from younger demographic for lack of hip ingredients |\n",
    "\n",
    "Meanwhile there's money being left on the table (their opportunities) with calamities (their threats) waiting in the wings to possibly happen and may knock their pizza shop out cold.\n",
    "\n",
    "### 🔖 Opportunities and Threats\n",
    "\n",
    "| **Opportunities**                                 | **Threats**                                                  |\n",
    "| --- | ---|\n",
    "| Untapped catering potential                       | Rising competition from cheaper pizza businesses nearby |\n",
    "| Growing local tech startup community              | There's nearby street construction that will impact foot traffic |\n",
    "| Unexplored online presence and order capabilities | Rising cost of cheese                                        |\n",
    "| Upcoming annual food fair                         | No immediate local regulatory changes but it's election season |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7977e7f7-2100-4fdc-a348-c9fbe1ac3a82",
   "metadata": {},
   "source": [
    "## 🤷 What does this have to do with LLMs and Semantic Kernel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fc96293-899c-4438-a891-7bccd0621630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made a kernel!\n"
     ]
    }
   ],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, OpenAIChatCompletion\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = False\n",
    "\n",
    "if useAzureOpenAI:\n",
    "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"azureopenai\", AzureChatCompletion(deployment, endpoint, api_key))\n",
    "else:\n",
    "    api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    kernel.add_text_completion_service(\"openai\", OpenAIChatCompletion(\"gpt-3.5-turbo-0301\", api_key))\n",
    "    # api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "    # kernel.add_text_completion_service(\"openai\", OpenAIChatCompletion(\"gpt-3.5-turbo-0301\", api_key, org_id))\n",
    "print(\"Made a kernel!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "193f0f62-913f-49cd-a592-5ffb33a2a96a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### ✨ Shift the SWOT interview questions to the world of software development\n",
       "위의 분석을 소프트웨어 개발 비즈니스 도메인으로 변환하면 다음과 같습니다.\n",
       "\n",
       "1. **강점**\n",
       "    - 소프트웨어 개발에서 고유한 기술이나 알고리즘을 사용하는가?\n",
       "    - 개발자들의 기술과 경험이 충분한가?\n",
       "    - 로컬 지역에서 소프트웨어 개발 회사의 평판이 좋은가?\n",
       "    - 회사나 개발자의 위치나 특징이 고객을 끌어들이는가?\n",
       "2. **약점**\n",
       "    - 소프트웨어 개발에서 운영상의 문제가 있는가? (예: 느린 서비스, 높은 인력 이동률)\n",
       "    - 성장이나 개선을 제한하는 재정적 제약이 있는가?\n",
       "    - 제품 제공에서 빈틈이 있는가?\n",
       "    - 고객 불만이나 부정적인 리뷰가 있는가?\n",
       "3. **기회**\n",
       "    - 새로운 제품이나 서비스 (예: 새로운 앱, 클라우드 서비스)를 출시할 수 있는 기회가 있는가?\n",
       "    - 미처 다가오지 않은 고객 세그먼트나 시장 영역이 있는가?\n",
       "    - 새로운 기술이나 시스템이 비즈니스 운영을 개선할 수 있는가?\n",
       "    - 마케팅에 활용할 수 있는 파트너십이나 로컬 이벤트가 있는가?\n",
       "4. **위협**\n",
       "    - 주요 경쟁 업체가 누구이며 그들이 제공하는 것은 무엇인가?\n",
       "    - 지역 내 변화 (예: 건설, 인근 비즈니스 폐쇄)로 인한 부정적인 영향이 있는가?\n",
       "    - 산업 경제나 동향이 비즈니스에 부정적인 영향을 미칠 가능성이 있는가? (예: 증가하는 개발 비용)\n",
       "    - 규제나 법률의 변화로 인해 위험이 있는가? (예: 개인정보 보호, 저작권)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "swot_interview= \"\"\"\n",
    "1. **Strengths**\n",
    "    - What unique recipes or ingredients does the pizza shop use?\n",
    "    - What are the skills and experience of the staff?\n",
    "    - Does the pizza shop have a strong reputation in the local area?\n",
    "    - Are there any unique features of the shop or its location that attract customers?\n",
    "2. **Weaknesses**\n",
    "    - What are the operational challenges of the pizza shop? (e.g., slow service, high staff turnover)\n",
    "    - Are there financial constraints that limit growth or improvements?\n",
    "    - Are there any gaps in the product offering?\n",
    "    - Are there customer complaints or negative reviews that need to be addressed?\n",
    "3. **Opportunities**\n",
    "    - Is there potential for new products or services (e.g., catering, delivery)?\n",
    "    - Are there under-served customer segments or market areas?\n",
    "    - Can new technologies or systems enhance the business operations?\n",
    "    - Are there partnerships or local events that can be leveraged for marketing?\n",
    "4. **Threats**\n",
    "    - Who are the major competitors and what are they offering?\n",
    "    - Are there potential negative impacts due to changes in the local area (e.g., construction, closure of nearby businesses)?\n",
    "    - Are there economic or industry trends that could impact the business negatively (e.g., increased ingredient costs)?\n",
    "    - Is there any risk due to changes in regulations or legislation (e.g., health and safety, employment)?\"\"\"\n",
    "\n",
    "\n",
    "sk_prompt = \"\"\"\n",
    "{{$input}}\n",
    "\n",
    "Convert the analysis provided above to the business domain of {{$domain}}. Reply in Korean\n",
    "\"\"\"\n",
    "shift_domain_function = kernel.create_semantic_function(prompt_template=sk_prompt,\n",
    "                                                    description=\"Translate an idea to another domain.\",\n",
    "                                                    max_tokens=1000,\n",
    "                                                    temperature=0.1,\n",
    "                                                    top_p=0.5)\n",
    "my_context = kernel.create_new_context()\n",
    "\n",
    "my_context['input'] = swot_interview\n",
    "# my_context['domain'] = \"construction management\"\n",
    "my_context['domain'] = \"software development\"\n",
    "\n",
    "result = await kernel.run_async(shift_domain_function, input_context=my_context)\n",
    "\n",
    "display(Markdown(f\"### ✨ Shift the SWOT interview questions to the world of {my_context['domain']}\\n\"+ str(result)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2cc70ab-d0b3-4093-8440-ca6c380fea6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### ✨ Shift the SWOT interview questions to the world of software development at the level of cto\n",
       "위의 분석을 CTO가 이해할 수 있도록 소프트웨어 개발 비즈니스 도메인으로 다음과 같이 재구성합니다.\n",
       "\n",
       "1. **강점**\n",
       "    - 기술적 우위: 소프트웨어 개발에서 고유한 기술이나 알고리즘을 사용하는가?\n",
       "    - 인력 우수성: 개발자들의 기술과 경험이 충분한가?\n",
       "    - 평판: 로컬 지역에서 소프트웨어 개발 회사의 평판이 좋은가?\n",
       "    - 독특한 제품/서비스: 고객을 유치하는 독특한 제품이나 서비스가 있는가?\n",
       "2. **약점**\n",
       "    - 운영상 문제: 소프트웨어 개발에서 운영상의 문제가 있는가? (예: 느린 서비스, 높은 인력 유동성)\n",
       "    - 재정적 제약: 성장이나 개선을 제한하는 재정적 제약이 있는가?\n",
       "    - 제품 라인업 빈틈: 제품 라인업에 빈틈이 있는가?\n",
       "    - 고객 불만/부정적 리뷰: 고객 불만이나 부정적인 리뷰가 있는가?\n",
       "3. **기회**\n",
       "    - 새로운 제품/서비스 출시: 새로운 제품이나 서비스 (예: 컨설팅, 클라우드 서비스)를 출시할 수 있는 기회가 있는가?\n",
       "    - 미처 다가오지 못한 고객 세그먼트/시장 영역: 미처 다가오지 못한 고객 세그먼트나 시장 영역이 있는가?\n",
       "    - 기술/시스템 개선: 새로운 기술이나 시스템이 비즈니스 운영을 개선할 수 있는가?\n",
       "    - 마케팅 파트너십/로컬 이벤트: 마케팅에 활용할 수 있는 파트너십이나 로컬 이벤트가 있는가?\n",
       "4. **위협**\n",
       "    - 경쟁 업체: 주요 경쟁 업체가 누구이며 어떤 제품이나 서비스를 제공하는가?\n",
       "    - 지역 변화: 지역 내 변화 (예: 건설, 인근 비즈니스 폐쇄)로 인한 부정적인 영향이 있는가?\n",
       "    - 산업 경제/트렌드 변화: 산업 경제나 트렌드 변화로 인해 비즈니스에 부정적인 영향을 미칠 가능성이 있는가? (예: 증가하는 개발 비용)\n",
       "    - 규제/법률 변경: 규제나 법률 변경으로 인해 위험이 있는가? (예: 개인정보 보호, 저작권)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sk_prompt = \"\"\"\n",
    "{{$input}}\n",
    "\n",
    "Rewrite the text above to be understood by a {{$level}}. Rewrite in Korean.\n",
    "\"\"\"\n",
    "shift_reading_level_function = kernel.create_semantic_function(prompt_template=sk_prompt,\n",
    "                                                    description=\"Change the reading level of a given text.\",\n",
    "                                                    max_tokens=1000,\n",
    "                                                    temperature=0.1,\n",
    "                                                    top_p=0.5)\n",
    "\n",
    "my_context['input'] = swot_interview\n",
    "my_context['domain'] = \"software development\"\n",
    "my_context[\"level\"] = \"cto\"\n",
    "\n",
    "result = await kernel.run_async(shift_domain_function, shift_reading_level_function, input_context=my_context)\n",
    "\n",
    "display(Markdown(f\"### ✨ Shift the SWOT interview questions to the world of {my_context['domain']} at the level of {my_context['level']}\\n\"+ str(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0172ab77-cfa1-40a5-adb0-7dcf4c568d4b",
   "metadata": {},
   "source": [
    "## 🔖 Reminder: All ✨ generative responses result from having the model fill in the _____.\n",
    "\n",
    "![](./assets/completion.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d060b98f-8d3f-43c8-bb2a-f6f2529b358c",
   "metadata": {},
   "source": [
    "Reminder: Download your notebook to your computer if you wish to save your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472872c4-c2de-4bea-a03c-b939618fbe1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
