{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b763b445",
   "metadata": {},
   "source": [
    "# Chains in LangChain\n",
    "\n",
    "## Outline\n",
    "\n",
    "* LLMChain\n",
    "* Sequential Chains\n",
    "  * SimpleSequentialChain\n",
    "  * SequentialChain\n",
    "* Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5361e8b6-ef4c-43d4-89d1-21249266be2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-dotenv\n",
    "# !pip install openai\n",
    "# !pip install promptlayer\n",
    "# !pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2fce8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a80376cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "# os.environ[\"LANGCHAIN_PROJECT\"] = \"DEEPLEARNING.AI\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = \"ls__a60ef12993333333333333\"\n",
    "\n",
    "# os.environ[\"LANGCHAIN_ENDPOINT\"] = \"http://localhost:1984\"\n",
    "# os.environ[\"LANGCHAIN_PROJECT\"] = \"DEEPLEARNING.AI\"\n",
    "\n",
    "# Google Colab와 같이 환경 변수에 설정이 어려운 경우 아래 주석을 제거한 값을 설정\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "# os.environ[\"PROMPTLAYER_API_KEY\"] = \"pl_43flkdsjfladjfldsa72b636\"\n",
    "# openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc5235e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b145f08-9a0f-4655-bd05-84d1331ce577",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '.'\n",
    "\n",
    "# Google Colab를 사용하는 경우 아래 코드의 주석을 제거한 다음 실행하여야 함\n",
    "# from google.colab import drive\n",
    "# drive.mount('/gdrive')\n",
    "# base_dir = '/gdrive/My Drive/Colab Notebooks/DeepLearning.AI/03.LangChain for LLM Application Development'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2de44e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(base_dir + '/Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d98951de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Queen Size Sheet Set</td>\n",
       "      <td>I ordered a king size set. My only criticism w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waterproof Phone Pouch</td>\n",
       "      <td>I loved the waterproof sac, although the openi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luxury Air Mattress</td>\n",
       "      <td>This mattress had a small hole in the top of i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pillows Insert</td>\n",
       "      <td>This is the best throw pillow fillers on Amazo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milk Frother Handheld\\n</td>\n",
       "      <td>I loved this product. But they only seem to l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Product                                             Review\n",
       "0     Queen Size Sheet Set  I ordered a king size set. My only criticism w...\n",
       "1   Waterproof Phone Pouch  I loved the waterproof sac, although the openi...\n",
       "2      Luxury Air Mattress  This mattress had a small hole in the top of i...\n",
       "3           Pillows Insert  This is the best throw pillow fillers on Amazo...\n",
       "4  Milk Frother Handheld\\n   I loved this product. But they only seem to l..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044a352b",
   "metadata": {},
   "source": [
    "## LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f1abc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI, PromptLayerChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3452339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatOpenAI(temperature=0.9)\n",
    "llm = PromptLayerChatOpenAI(pl_tags=[\"langchain_231030\"], temperature=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f598b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad5ebc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ba9b261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Royal Comfort Bedding'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = \"Queen Size Sheet Set\"\n",
    "chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de7d2e4",
   "metadata": {},
   "source": [
    "## SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa195ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "366eb6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatOpenAI(temperature=0.9)\n",
    "llm = PromptLayerChatOpenAI(pl_tags=[\"langchain_231030\"], temperature=0.9)\n",
    "\n",
    "# prompt template 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")  # \"{제품}을 만드는 회사를 설명하는 가장 좋은 이름은 무엇인가요?\"\n",
    "\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e41095a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20 words description in Korean for the following \\\n",
    "    company:{company_name}\"\n",
    ")  # \"다음 회사에 대한 한국어 설명을 20단어로 작성하세요:{company_name}\"\n",
    "\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2186b1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
    "                                             verbose=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "780e66ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mRoyal Rest Linens\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m로얄 레스트 린넨즈는 고품질의 침구류를 제공하는 기업으로, 편안한 잠자리를 위한 최적의 선택입니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'로얄 레스트 린넨즈는 고품질의 침구류를 제공하는 기업으로, 편안한 잠자리를 위한 최적의 선택입니다.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_simple_chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5648c727",
   "metadata": {},
   "source": [
    "## SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb53086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e4874c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatOpenAI(temperature=0.9)\n",
    "llm = PromptLayerChatOpenAI(pl_tags=[\"langchain_231030\"], temperature=0.9)\n",
    "\n",
    "# prompt template 1: translate to english\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following review to Korean:\"\n",
    "    \"\\n\\n{Review}\"\n",
    ")\n",
    "# chain 1: input= Review and output= English_Review\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key=\"Korean_Review\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "890c6cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Can you summarize the following review in 1 sentence in Korean:\"\n",
    "    \"\\n\\n{Korean_Review}\"\n",
    ")\n",
    "# chain 2: input= English_Review and output= summary\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key=\"summary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5bf60750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 3: translate to english\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What language is the following review:\\n\\n{Review}\"\n",
    ")\n",
    "# chain 3: input= Review and output= language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key=\"language\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b7d9dee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prompt template 4: follow up message\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow up response to the following \"\n",
    "    \"summary in the specified language:\"\n",
    "    \"\\n\\nSummary: {summary}\\n\\nLanguage: {language}\"\n",
    ")\n",
    "# chain 4: input= summary, language and output= followup_message\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key=\"followup_message\"\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1936158-ba96-4511-ba30-33a830926659",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prompt template 5: follow up message\n",
    "fifth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow up response to the following \"\n",
    "    \"summary in the specified language:\"\n",
    "    \"\\n\\nSummary: {summary}\\n\\nLanguage: ko\"\n",
    ")\n",
    "# chain 4: input= summary, language and output= followup_message\n",
    "chain_five = LLMChain(llm=llm, prompt=fifth_prompt,\n",
    "                      output_key=\"followup_message_ko\"\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a420638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_chain: input= Review \n",
    "# and output= English_Review,summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four, chain_five],\n",
    "    input_variables=[\"Review\"],\n",
    "    output_variables=[\"Korean_Review\", \"summary\",\"followup_message_ko\",\"followup_message\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f776bd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Review': \"Je trouve le goût médiocre. La mousse ne tient pas, c'est bizarre. J'achète les mêmes dans le commerce et le goût est bien meilleur...\\nVieux lot ou contrefaçon !?\",\n",
       " 'Korean_Review': '저는 맛이 별로라고 생각합니다. 거품이 잘 유지되지 않아 이상합니다. 상점에서 같은 제품을 구입하는데 맛이 훨씬 좋습니다...\\n오래된 로트인가요, 아니면 모조품인가요!?',\n",
       " 'summary': '이 사용자는 이 제품의 맛이 별로라고 생각하고 거품이 잘 유지되지 않아 이상하다고 말하며, 같은 제품을 상점에서 구입한 것이 훨씬 맛있다고 언급하며, 이 제품이 오래된 로트인지 아니면 모조품인지 궁금해 한다.',\n",
       " 'followup_message_ko': '안녕하세요,\\n\\n저희 제품에 대한 소중한 의견을 남겨주셔서 감사합니다. 이용자님의 맛에 대한 평가와 거품의 유지에 대한 의견을 주셨는데, 정말로 유용한 정보입니다.\\n\\n첫째로, 맛에 대한 문제에 대해서는 죄송합니다. 이 제품이 다른 맛을 가질 수 있는 경우가 있다는 점에 대해 인식하게 되었고, 이를 개선하기 위해 노력하고자 합니다. 더 많은 개발 및 테스트를 통해 우수한 맛을 확보하는 방법을 연구할 것입니다.\\n\\n둘째로, 거품의 유지에 대한 문제도 인식하고 있습니다. 저희는 거품이 오래 유지되도록 제품을 개선하는 방법을 고려하고 있습니다. 추가적인 조치를 취하기 위해 노력할 것입니다.\\n\\n마지막으로, 이 제품이 오래된 로트인지 아니면 모조품인지에 대한 궁금증을 해소하기 위해 곧 답변을 드리도록 하겠습니다. 추가적인 정보를 얻은 후에는 빠른 시일 내에 연락드리도록 하겠습니다.\\n\\n이용자님의 의견은 저희에게 매우 중요하며, 고객님의 만족도 향상을 위해 최선을 다하겠습니다. 다시 한번 소중한 의견을 남겨주셔서 감사드립니다.\\n\\n좋은 하루 되세요.\\n\\n감사합니다.',\n",
       " 'followup_message': \"Réponse: Merci d'avoir partagé votre avis sur notre produit. Nous sommes désolés d'apprendre que vous n'avez pas apprécié son goût et que la mousse ne se maintient pas bien. Nous tenons à vous assurer que notre produit est authentique et de haute qualité. Cependant, il est possible que vous ayez obtenu un lot défectueux. Pourriez-vous nous fournir plus d'informations, telles que le numéro de lot et la date d'expiration, afin que nous puissions enquêter davantage sur ce problème? Nous vous invitons également à visiter notre magasin pour acheter le même produit dont vous parlez et comparer les résultats. Votre satisfaction est très importante pour nous et nous ferons tout notre possible pour résoudre ce problème. Merci encore pour vos commentaires et votre soutien.\"}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = df.Review[5]\n",
    "overall_chain(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a85c70-e888-44a6-ba27-0389862e3f18",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 결과\n",
    "```\n",
    "{'Review': \"Je trouve le goût médiocre. La mousse ne tient pas, c'est bizarre. J'achète les mêmes dans le commerce et le goût est bien meilleur...\\nVieux lot ou contrefaçon !?\",\n",
    " 'Korean_Review': '저는 맛이 별로라고 생각합니다. 거품이 유지되지 않는 것이 이상하네요. 상점에서 똑같은 제품을 사 먹어도 맛이 훨씬 좋은데요...\\n오래된 제품이거나 위조품인가요!?',\n",
    " 'summary': '이 리뷰는 맛이 별로하고 거품이 유지되지 않아 이상하다는데, 상점에서 먹었던 똑같은 제품은 맛이 훨씬 좋았는데, 이 제품이 오래된 것이거나 위조품인지 궁금합니다.',\n",
    " 'followup_message_ko': '안녕하세요,\\n\\n이 리뷰를 읽어주셔서 감사합니다. 저희는 맛과 거품 유지에 대한 문제를 경험하셨다고 알려주셔서 유감입니다. 저희 제품은 항상 최상의 품질을 유지하고자 노력하고 있으므로 이러한 상황이 발생한 것에 대해 사과의 말씀을 드립니다.\\n\\n예상하신 대로, 이 제품이 오래된 것이거나 위조품이 아닌지에 대해 궁금해하시는 것은 당연한 일입니다. 저희는 정품 제품을 판매하기 위해 노력하고 있으며, 이러한 문제가 발생하지 않도록 철저한 품질 관리 절차를 따르고 있습니다.\\n\\n고객님의 견해를 좀 더 이해하기 위해 상세한 정보와 구매하신 제품의 사진을 제공해주시면, 저희는 더 자세한 조사를 진행하여 문제를 해결하고 최고의 서비스를 제공할 수 있도록 노력하겠습니다.\\n\\n다시 한번 관심을 가져주셔서 감사드리며, 빠른 답변을 드리기 위해 기다리고 있겠습니다.\\n\\n좋은 하루 되세요.\\n\\n문의팀',\n",
    " 'followup_message': \"Cher(e) utilisateur(trice), \\n\\nNous avons bien pris en compte votre commentaire sur la mauvaise qualité du produit et la non-persistence de la mousse. Nous nous excusons pour cette expérience désagréable.\\n\\nNous tenons à vous assurer que nos produits sont authentiques et de haute qualité. Si vous avez déjà consommé le même produit dans notre magasin et qu'il était de bien meilleure qualité, il est possible que le produit que vous avez reçu soit périmé ou altéré.\\n\\nAfin de résoudre ce problème, nous vous invitons à nous contacter directement avec les détails de votre achat, y compris votre nom et la date d'achat. Nous souhaitons résoudre cette situation de manière satisfaisante pour vous.\\n\\nNous sommes désolés pour les désagréments causés et espérons pouvoir rectifier cette situation rapidement.\\n\\nCordialement,\\nL'équipe du service client.\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecc19a9",
   "metadata": {},
   "source": [
    "## Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5a1159e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise\\\n",
    "and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit\\\n",
    "that you don't know.\n",
    "You must reply in Korean.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. \\\n",
    "You are great at answering math questions. \\\n",
    "You are so good because you are able to break down \\\n",
    "hard problems into their component parts, \n",
    "answer the component parts, and then put them together\\\n",
    "to answer the broader question.\n",
    "You must reply in Korean.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "history_template = \"\"\"You are a very good historian. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods. \\\n",
    "You have the ability to think, reflect, debate, discuss and \\\n",
    "evaluate the past. You have a respect for historical evidence\\\n",
    "and the ability to make use of it to support your explanations \\\n",
    "and judgements.\n",
    "You must reply in Korean.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "computerscience_template = \"\"\" You are a successful computer scientist.\\\n",
    "You have a passion for creativity, collaboration,\\\n",
    "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
    "understanding of theories and algorithms, and excellent communication \\\n",
    "skills. You are great at answering coding questions. \\\n",
    "You are so good because you know how to solve a problem by \\\n",
    "describing the solution in imperative steps \\\n",
    "that a machine can easily interpret and you know how to \\\n",
    "choose a solution that has a good balance between \\\n",
    "time complexity and space complexity. \n",
    "You must reply in Korean.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a258ff9-da2c-484b-865a-a57f1aa71a53",
   "metadata": {},
   "source": [
    "## 프롬프트 번역 \n",
    "```\n",
    "physics_template = \"\"\"당신은 매우 똑똑한 물리학 교수입니다.\n",
    "당신은 물리학에 대한 질문에 간결하고 이해하기 쉬운 방식으로\n",
    "간결하고 이해하기 쉽게 대답합니다.\n",
    "질문에 대한 답을 모를 때는 자신이 모른다고 인정합니다.\n",
    "모른다고 인정합니다.\n",
    "\n",
    "여기 질문이 있습니다:\n",
    "{입력}\"\"\"\n",
    "\n",
    "math_template = \"\"\"당신은 아주 훌륭한 수학자입니다.\n",
    "귀하는 수학 문제에 대한 답을 잘 맞힙니다.\n",
    "당신은 어려운 문제를 구성 요소로 분해할 수 있기 때문에 당신은 매우 훌륭합니다.\n",
    "어려운 문제를 구성 요소로 나눌 수 있기 때문입니다,\n",
    "그 구성 요소에 답한 다음, 그것들을 종합하여\n",
    "더 넓은 질문에 답할 수 있기 때문입니다.\n",
    "\n",
    "여기 질문이 있습니다:\n",
    "{입력}\"\"\"\n",
    "\n",
    "history_template = \"\"\"당신은 아주 훌륭한 역사가입니다.\n",
    "다양한 역사적 시기의 인물, 사건, 상황에 대한 지식과 이해가 뛰어납니다.\n",
    "다양한 역사적 시기의 사건과 맥락에 대한 지식과 이해가 뛰어납니다.\n",
    "귀하는 생각하고, 반성하고, 토론하고, 토론하고, 과거를 평가할 수 있는 능력이 있습니다.\n",
    "과거를 평가할 수 있습니다. 역사적 증거를 존중하고\n",
    "역사적 증거를 존중하고 이를 활용하여 자신의 설명과 판단을 뒷받침할 수 있습니다.\n",
    "판단을 뒷받침할 수 있습니다.\n",
    "\n",
    "여기 질문이 있습니다:\n",
    "{입력}\"\"\"\n",
    "\n",
    "computerscience_template = \"\"\" 귀하는 성공적인 컴퓨터 과학자입니다.\n",
    "귀하는 창의성, 협업에 대한 열정, 미래 지향적 사고, 자신감, 강력한 문제 해결 능력을 갖추고 있습니다.\n",
    "미래 지향적 사고, 자신감, 강력한 문제 해결 능력, 이론 및 알고리즘에 대한 이해, \n",
    "이론과 알고리즘에 대한 이해, 뛰어난 의사 소통 능력\n",
    "기술. 코딩 질문에 답하는 데 능숙합니다.\n",
    "당신은 문제를 해결하는 방법을 알고 있기 때문에 매우 훌륭합니다.\n",
    "해결책을 필수 단계로 설명하여 문제를 해결하는 방법을 알고 있기 때문입니다.\n",
    "기계가 쉽게 해석할 수 있는 방법을 알고 있고\n",
    "시간 복잡성과 공간 복잡성 사이의 균형이 잘 잡힌 솔루션을 선택하는 방법을 알고 있기 때문입니다.\n",
    "균형이 잘 잡힌 솔루션을 선택하는 방법을 알고 있기 때문입니다.\n",
    "\n",
    "다음은 질문입니다:\n",
    "{입력}\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "14179545",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\", \n",
    "        \"description\": \"Good for answering questions about physics\", \n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\", \n",
    "        \"description\": \"Good for answering math questions\", \n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"History\", \n",
    "        \"description\": \"Good for answering history questions\", \n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer science\", \n",
    "        \"description\": \"Good for answering computer science questions\", \n",
    "        \"prompt_template\": computerscience_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ebd4cae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0b0ff3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatOpenAI(temperature=0)\n",
    "llm = PromptLayerChatOpenAI(pl_tags=[\"langchain_231030\"], temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c1b60877",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4cf427d5-bf96-41de-bb04-642a914152fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'physics: Good for answering questions about physics\\nmath: Good for answering math questions\\nHistory: Good for answering history questions\\ncomputer science: Good for answering computer science questions'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destinations_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6b09c35c-83a3-456b-8232-4c98b923d2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"\"\"You must reply in Korean.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "563f0ef9-e0bc-4684-9b2a-a7f997cdb991",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d590bd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f609e185-6c79-443b-bb55-a2ed625b4439",
   "metadata": {},
   "source": [
    "## 프롬프트 번역\n",
    "```\n",
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"원시 텍스트 입력이 주어지면 \\\n",
    "언어 모델에 원시 텍스트 입력이 주어지면 입력에 가장 적합한 모델 프롬프트를 선택합니다. \\\n",
    "사용 가능한 프롬프트의 이름과 가장 적합한 프롬프트가 무엇인지에 대한 \\\"\n",
    "프롬프트의 이름과 해당 프롬프트가 가장 적합한 항목에 대한 설명이 제공됩니다. \\\n",
    "원래 입력을 수정하는 것이 궁극적으로 더 나은 응답으로 이어질 것이라고 생각되면 \\원래 입력을 수정할 수도 있습니다.\n",
    "수정하는 것이 궁극적으로 언어 모델에서 더 나은 응답을 얻을 수 있다고 생각되면 수정할 수도 있습니다.\n",
    "\n",
    "<< FORMATTING >>\n",
    "다음과 같은 형식의 JSON 객체가 포함된 마크다운 코드 스니펫을 반환합니다:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ 사용할 프롬프트의 이름 또는 \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ 원본 입력의 잠재적으로 수정된 버전\n",
    "}}}}\n",
    "```\n",
    "\n",
    "참고: \"대상\"은 아래에 지정된 후보 프롬프트 \\\n",
    "아래에 지정된 이름 중 하나이거나, 입력이 후보 프롬프트 중 하나에 \\\"적합하지 않은 경우 \\\"DEFAULT\" 일 수 있습니다.\n",
    "후보 프롬프트 중 하나에 적합하지 않은 경우 \"DEFAULT\"일 수 있습니다.\n",
    "기억하세요: \"next_inputs\"는 원래 입력일 수도 있습니다.\n",
    "그대로 사용할 수 있습니다.\n",
    "\n",
    "<< 후보 프롬프트 >>\n",
    "{대상}\n",
    "\n",
    "<< 입력 >>\n",
    "{입력}}\n",
    "\n",
    "<< OUTPUT (```json)>>\"\"\"을 포함해야 함을 잊지 마세요.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "147763e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0ed6707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b0fcbdb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': 'What is black body radiation?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'블랙 바디 방사선은 모든 물체가 방출하는 열 방사선입니다. 블랙 바디는 모든 입자와 전자를 완벽하게 흡수하고 반사하지 않는 가상의 물체로 가정됩니다. 이 물체는 온도에 따라 특정한 스펙트럼으로 열 에너지를 방출하는데, 이를 블랙 바디 방사선이라고 합니다. 블랙 바디 방사선은 맥스 플랑크와 아인슈타인의 연구를 통해 이해되었으며, 많은 물리적 현상과 관련이 있습니다.'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What is black body radiation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "328803a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "math: {'input': \"what is Fermat's Last Theorem\"}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'페르마의 마지막 정리는 매우 유명한 수학 문제로, 피에르 드 페르마(Fermat)가 제시한 문제입니다. 이 정리는 다음과 같이 말합니다: 어떤 자연수 n이 2보다 큰 경우, 다음 방정식은 정수해를 갖지 않습니다.\\n\\nx^n + y^n = z^n\\n\\n이 정리는 약 350년 동안 증명되지 못한 문제로 여겨졌습니다. 그러나 1995년에 앤드루 와일즈(Andrew Wiles)가 이 문제를 해결하였으며, 예메르 소식으로 알려졌습니다.\\n\\n따라서, 페르마의 마지막 정리는 x^n + y^n = z^n 의 정수해가 존재하지 않음을 말합니다.'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"what is Fermat's Last Theorem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c4d5fe8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "None: {'input': 'Why does every cell in our body contain DNA?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'모든 세포가 우리의 신체에 DNA를 포함하는 이유는 무엇인가요?'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Why does every cell in our body contain DNA?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "28e4793b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "None: {'input': 'how to make kimchi'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'김치를 만드는 방법에는 몇 가지 단계가 있습니다. 먼저, 재료를 준비해야 합니다. 배추, 고추 가루, 소금, 다진 마늘, 생강, 청주, 멸치 액젓, 배추 꼬기 등이 필요합니다.\\n\\n1. 배추는 중간 크기로 골라 외부 잎을 제거하고 안쪽 잎들을 떼어냅니다. 떼어낸 잎들에 소금을 뿌려 잘 버무린 뒤 2-3시간 정도 절여 두고 푹 썬 뒤 흔들어 물기를 제거해줍니다.\\n\\n2. 고추 가루, 다진 마늘, 다진 생강, 청주, 멸치 액젓을 함께 섞어 마른 잎들에 고루 바른 뒤 잎을 말아 꼬꼬마 크기로 썰어줍니다.\\n\\n3. 꼬꼬마로 썬 김치를 용기에 담은 후, 끓인 물에 멸치를 우려 내고 식힌 다음 멸치 육수를 김치 위에 부어줍니다.\\n\\n4. 용기에 담긴 김치를 약 1-2일 동안 방 온에서 발효시켜주세요. 그 후 냉장고에 보관하면 오랫동안 맛있게 먹을 수 있습니다.\\n\\n이렇게하면 기본적인 김치를 만들 수 있습니다. 추가적으로 다양한 재료를 활용하여 다른 종류의 김치도 만들 수 있으니 참고하시기 바랍니다.'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"how to make kimchi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afc48ea-0d40-4f8e-9946-ea0645bf86d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
