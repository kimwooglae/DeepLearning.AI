{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b763b445",
   "metadata": {},
   "source": [
    "# Chains in LangChain\n",
    "\n",
    "## Outline\n",
    "\n",
    "* LLMChain\n",
    "* Sequential Chains\n",
    "  * SimpleSequentialChain\n",
    "  * SequentialChain\n",
    "* Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5361e8b6-ef4c-43d4-89d1-21249266be2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-dotenv\n",
    "# !pip install openai\n",
    "# !pip install promptlayer\n",
    "# !pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2fce8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a80376cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "# os.environ[\"LANGCHAIN_PROJECT\"] = \"DEEPLEARNING.AI\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = \"ls__a60ef12993333333333333\"\n",
    "\n",
    "# os.environ[\"LANGCHAIN_ENDPOINT\"] = \"http://localhost:1984\"\n",
    "# os.environ[\"LANGCHAIN_PROJECT\"] = \"DEEPLEARNING.AI\"\n",
    "\n",
    "# Google Colab와 같이 환경 변수에 설정이 어려운 경우 아래 주석을 제거한 값을 설정\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "# os.environ[\"PROMPTLAYER_API_KEY\"] = \"pl_43flkdsjfladjfldsa72b636\"\n",
    "# openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc5235e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b145f08-9a0f-4655-bd05-84d1331ce577",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '.'\n",
    "\n",
    "# Google Colab를 사용하는 경우 아래 코드의 주석을 제거한 다음 실행하여야 함\n",
    "# from google.colab import drive\n",
    "# drive.mount('/gdrive')\n",
    "# base_dir = '/gdrive/My Drive/Colab Notebooks/DeepLearning.AI/03.LangChain for LLM Application Development'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2de44e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(base_dir + '/Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d98951de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Queen Size Sheet Set</td>\n",
       "      <td>I ordered a king size set. My only criticism w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waterproof Phone Pouch</td>\n",
       "      <td>I loved the waterproof sac, although the openi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luxury Air Mattress</td>\n",
       "      <td>This mattress had a small hole in the top of i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pillows Insert</td>\n",
       "      <td>This is the best throw pillow fillers on Amazo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milk Frother Handheld\\n</td>\n",
       "      <td>I loved this product. But they only seem to l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Product                                             Review\n",
       "0     Queen Size Sheet Set  I ordered a king size set. My only criticism w...\n",
       "1   Waterproof Phone Pouch  I loved the waterproof sac, although the openi...\n",
       "2      Luxury Air Mattress  This mattress had a small hole in the top of i...\n",
       "3           Pillows Insert  This is the best throw pillow fillers on Amazo...\n",
       "4  Milk Frother Handheld\\n   I loved this product. But they only seem to l..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044a352b",
   "metadata": {},
   "source": [
    "## LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f1abc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI, PromptLayerChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3452339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatOpenAI(temperature=0.9)\n",
    "llm = PromptLayerChatOpenAI(pl_tags=[\"langchain_231030\"], temperature=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f598b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad5ebc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ba9b261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"RegalRest\"'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = \"Queen Size Sheet Set\"\n",
    "chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de7d2e4",
   "metadata": {},
   "source": [
    "## SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa195ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "366eb6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatOpenAI(temperature=0.9)\n",
    "llm = PromptLayerChatOpenAI(pl_tags=[\"langchain_231030\"], temperature=0.9)\n",
    "\n",
    "# prompt template 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")  # \"{제품}을 만드는 회사를 설명하는 가장 좋은 이름은 무엇인가요?\"\n",
    "\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e41095a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20 words description in Korean for the following \\\n",
    "    company:{company_name}\"\n",
    ")  # \"다음 회사에 대한 한국어 설명을 20단어로 작성하세요:{company_name}\"\n",
    "\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2186b1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
    "                                             verbose=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "780e66ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mRoyal Beddings\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m로열 베딩은 고품질의 침구 제품을 제공하는 회사로, 편안한 수면 환경을 제공합니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'로열 베딩은 고품질의 침구 제품을 제공하는 회사로, 편안한 수면 환경을 제공합니다.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_simple_chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5648c727",
   "metadata": {},
   "source": [
    "## SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb53086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e4874c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatOpenAI(temperature=0.9)\n",
    "llm = PromptLayerChatOpenAI(pl_tags=[\"langchain_231030\"], temperature=0.9)\n",
    "\n",
    "# prompt template 1: translate to english\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following review to Korean:\"\n",
    "    \"\\n\\n{Review}\"\n",
    ")\n",
    "# chain 1: input= Review and output= English_Review\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key=\"Korean_Review\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "890c6cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Can you summarize the following review in 1 sentence in Korean:\"\n",
    "    \"\\n\\n{Korean_Review}\"\n",
    ")\n",
    "# chain 2: input= English_Review and output= summary\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key=\"summary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bf60750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 3: translate to english\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What language is the following review:\\n\\n{Review}\"\n",
    ")\n",
    "# chain 3: input= Review and output= language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key=\"language\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7d9dee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prompt template 4: follow up message\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow up response to the following \"\n",
    "    \"summary in the specified language:\"\n",
    "    \"\\n\\nSummary: {summary}\\n\\nLanguage: {language}\"\n",
    ")\n",
    "# chain 4: input= summary, language and output= followup_message\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key=\"followup_message\"\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1936158-ba96-4511-ba30-33a830926659",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prompt template 5: follow up message\n",
    "fifth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow up response to the following \"\n",
    "    \"summary in the specified language:\"\n",
    "    \"\\n\\nSummary: {summary}\\n\\nLanguage: ko\"\n",
    ")\n",
    "# chain 4: input= summary, language and output= followup_message\n",
    "chain_five = LLMChain(llm=llm, prompt=fifth_prompt,\n",
    "                      output_key=\"followup_message_ko\"\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a420638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_chain: input= Review \n",
    "# and output= English_Review,summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four, chain_five],\n",
    "    input_variables=[\"Review\"],\n",
    "    output_variables=[\"Korean_Review\", \"summary\",\"followup_message_ko\",\"followup_message\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f776bd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Review': \"Je trouve le goût médiocre. La mousse ne tient pas, c'est bizarre. J'achète les mêmes dans le commerce et le goût est bien meilleur...\\nVieux lot ou contrefaçon !?\",\n",
       " 'Korean_Review': '저는 맛이 별로인 것 같아요. 거품이 잘 유지되지 않고 이상하네요. 저는 같은 제품을 상점에서 살 때 맛이 훨씬 좋아요... 오래된 제품이거나 모조품인가요!?',\n",
       " 'summary': '이 리뷰에서는 제품의 맛이 별로이며 거품이 잘 유지되지 않아 이상하다고 언급했으며, 같은 제품을 상점에서 살 때는 맛이 훨씬 좋았으니 오래된 제품이거나 모조품인지 의심스럽다고 말하고 있습니다.',\n",
       " 'followup_message_ko': '안녕하세요,\\n\\n저희 제품에 대한 리뷰를 남겨주셔서 감사합니다. 맛과 거품에 대한 걱정 사항을 언급해 주셨는데, 이는 저희에게는 중요한 문제입니다. 또한, 상점에서 구매한 제품과 비교했을 때 차이가 있다고 언급하셨는데, 이는 제품의 오래된 상태 또는 모조품 가능성을 의심할 수 있습니다.\\n\\n우리는 이 문제를 해결하기 위해 관련 부서와 함께 조사를 진행할 것이며, 제품의 품질과 맛에 대한 안정성을 높일 것입니다. 혹시 제품에 문제가 있는 경우, 환불 또는 교환 등의 조치를 취할 수 있도록 도와드리겠습니다.\\n\\n고객님의 소중한 의견에 귀 기울이고, 개선을 위해 최선을 다할 것입니다. 다시 한 번 문제 발생에 대해 진심으로 사과드리며, 저희 제품에 대한 믿음을 회복시킬 수 있도록 노력하겠습니다.\\n\\n감사합니다.',\n",
       " 'followup_message': \"Réponse : Dans cette critique, l'utilisateur mentionne que le goût du produit n'est pas bon et que la mousse ne se maintient pas bien, ce qui est étrange. Il indique également que le goût était bien meilleur lorsqu'il l'a acheté en magasin, ce qui le fait soupçonner qu'il s'agisse d'un produit périmé ou contrefait.\"}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = df.Review[5]\n",
    "overall_chain(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a85c70-e888-44a6-ba27-0389862e3f18",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 결과\n",
    "```\n",
    "{'Review': \"Je trouve le goût médiocre. La mousse ne tient pas, c'est bizarre. J'achète les mêmes dans le commerce et le goût est bien meilleur...\\nVieux lot ou contrefaçon !?\",\n",
    " 'Korean_Review': '저는 맛이 별로라고 생각합니다. 거품이 유지되지 않는 것이 이상하네요. 상점에서 똑같은 제품을 사 먹어도 맛이 훨씬 좋은데요...\\n오래된 제품이거나 위조품인가요!?',\n",
    " 'summary': '이 리뷰는 맛이 별로하고 거품이 유지되지 않아 이상하다는데, 상점에서 먹었던 똑같은 제품은 맛이 훨씬 좋았는데, 이 제품이 오래된 것이거나 위조품인지 궁금합니다.',\n",
    " 'followup_message_ko': '안녕하세요,\\n\\n이 리뷰를 읽어주셔서 감사합니다. 저희는 맛과 거품 유지에 대한 문제를 경험하셨다고 알려주셔서 유감입니다. 저희 제품은 항상 최상의 품질을 유지하고자 노력하고 있으므로 이러한 상황이 발생한 것에 대해 사과의 말씀을 드립니다.\\n\\n예상하신 대로, 이 제품이 오래된 것이거나 위조품이 아닌지에 대해 궁금해하시는 것은 당연한 일입니다. 저희는 정품 제품을 판매하기 위해 노력하고 있으며, 이러한 문제가 발생하지 않도록 철저한 품질 관리 절차를 따르고 있습니다.\\n\\n고객님의 견해를 좀 더 이해하기 위해 상세한 정보와 구매하신 제품의 사진을 제공해주시면, 저희는 더 자세한 조사를 진행하여 문제를 해결하고 최고의 서비스를 제공할 수 있도록 노력하겠습니다.\\n\\n다시 한번 관심을 가져주셔서 감사드리며, 빠른 답변을 드리기 위해 기다리고 있겠습니다.\\n\\n좋은 하루 되세요.\\n\\n문의팀',\n",
    " 'followup_message': \"Cher(e) utilisateur(trice), \\n\\nNous avons bien pris en compte votre commentaire sur la mauvaise qualité du produit et la non-persistence de la mousse. Nous nous excusons pour cette expérience désagréable.\\n\\nNous tenons à vous assurer que nos produits sont authentiques et de haute qualité. Si vous avez déjà consommé le même produit dans notre magasin et qu'il était de bien meilleure qualité, il est possible que le produit que vous avez reçu soit périmé ou altéré.\\n\\nAfin de résoudre ce problème, nous vous invitons à nous contacter directement avec les détails de votre achat, y compris votre nom et la date d'achat. Nous souhaitons résoudre cette situation de manière satisfaisante pour vous.\\n\\nNous sommes désolés pour les désagréments causés et espérons pouvoir rectifier cette situation rapidement.\\n\\nCordialement,\\nL'équipe du service client.\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecc19a9",
   "metadata": {},
   "source": [
    "## Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a1159e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise\\\n",
    "and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit\\\n",
    "that you don't know.\n",
    "You must reply in Korean.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. \\\n",
    "You are great at answering math questions. \\\n",
    "You are so good because you are able to break down \\\n",
    "hard problems into their component parts, \n",
    "answer the component parts, and then put them together\\\n",
    "to answer the broader question.\n",
    "You must reply in Korean.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "history_template = \"\"\"You are a very good historian. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods. \\\n",
    "You have the ability to think, reflect, debate, discuss and \\\n",
    "evaluate the past. You have a respect for historical evidence\\\n",
    "and the ability to make use of it to support your explanations \\\n",
    "and judgements.\n",
    "You must reply in Korean.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "computerscience_template = \"\"\" You are a successful computer scientist.\\\n",
    "You have a passion for creativity, collaboration,\\\n",
    "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
    "understanding of theories and algorithms, and excellent communication \\\n",
    "skills. You are great at answering coding questions. \\\n",
    "You are so good because you know how to solve a problem by \\\n",
    "describing the solution in imperative steps \\\n",
    "that a machine can easily interpret and you know how to \\\n",
    "choose a solution that has a good balance between \\\n",
    "time complexity and space complexity. \n",
    "You must reply in Korean.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a258ff9-da2c-484b-865a-a57f1aa71a53",
   "metadata": {},
   "source": [
    "## 프롬프트 번역 \n",
    "```\n",
    "physics_template = \"\"\"당신은 매우 똑똑한 물리학 교수입니다.\n",
    "당신은 물리학에 대한 질문에 간결하고 이해하기 쉬운 방식으로\n",
    "간결하고 이해하기 쉽게 대답합니다.\n",
    "질문에 대한 답을 모를 때는 자신이 모른다고 인정합니다.\n",
    "모른다고 인정합니다.\n",
    "\n",
    "여기 질문이 있습니다:\n",
    "{입력}\"\"\"\n",
    "\n",
    "math_template = \"\"\"당신은 아주 훌륭한 수학자입니다.\n",
    "귀하는 수학 문제에 대한 답을 잘 맞힙니다.\n",
    "당신은 어려운 문제를 구성 요소로 분해할 수 있기 때문에 당신은 매우 훌륭합니다.\n",
    "어려운 문제를 구성 요소로 나눌 수 있기 때문입니다,\n",
    "그 구성 요소에 답한 다음, 그것들을 종합하여\n",
    "더 넓은 질문에 답할 수 있기 때문입니다.\n",
    "\n",
    "여기 질문이 있습니다:\n",
    "{입력}\"\"\"\n",
    "\n",
    "history_template = \"\"\"당신은 아주 훌륭한 역사가입니다.\n",
    "다양한 역사적 시기의 인물, 사건, 상황에 대한 지식과 이해가 뛰어납니다.\n",
    "다양한 역사적 시기의 사건과 맥락에 대한 지식과 이해가 뛰어납니다.\n",
    "귀하는 생각하고, 반성하고, 토론하고, 토론하고, 과거를 평가할 수 있는 능력이 있습니다.\n",
    "과거를 평가할 수 있습니다. 역사적 증거를 존중하고\n",
    "역사적 증거를 존중하고 이를 활용하여 자신의 설명과 판단을 뒷받침할 수 있습니다.\n",
    "판단을 뒷받침할 수 있습니다.\n",
    "\n",
    "여기 질문이 있습니다:\n",
    "{입력}\"\"\"\n",
    "\n",
    "computerscience_template = \"\"\" 귀하는 성공적인 컴퓨터 과학자입니다.\n",
    "귀하는 창의성, 협업에 대한 열정, 미래 지향적 사고, 자신감, 강력한 문제 해결 능력을 갖추고 있습니다.\n",
    "미래 지향적 사고, 자신감, 강력한 문제 해결 능력, 이론 및 알고리즘에 대한 이해, \n",
    "이론과 알고리즘에 대한 이해, 뛰어난 의사 소통 능력\n",
    "기술. 코딩 질문에 답하는 데 능숙합니다.\n",
    "당신은 문제를 해결하는 방법을 알고 있기 때문에 매우 훌륭합니다.\n",
    "해결책을 필수 단계로 설명하여 문제를 해결하는 방법을 알고 있기 때문입니다.\n",
    "기계가 쉽게 해석할 수 있는 방법을 알고 있고\n",
    "시간 복잡성과 공간 복잡성 사이의 균형이 잘 잡힌 솔루션을 선택하는 방법을 알고 있기 때문입니다.\n",
    "균형이 잘 잡힌 솔루션을 선택하는 방법을 알고 있기 때문입니다.\n",
    "\n",
    "다음은 질문입니다:\n",
    "{입력}\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14179545",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\", \n",
    "        \"description\": \"Good for answering questions about physics\", \n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\", \n",
    "        \"description\": \"Good for answering math questions\", \n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"History\", \n",
    "        \"description\": \"Good for answering history questions\", \n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer science\", \n",
    "        \"description\": \"Good for answering computer science questions\", \n",
    "        \"prompt_template\": computerscience_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebd4cae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b0ff3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatOpenAI(temperature=0)\n",
    "llm = PromptLayerChatOpenAI(pl_tags=[\"langchain_231030\"], temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1b60877",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4cf427d5-bf96-41de-bb04-642a914152fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'physics: Good for answering questions about physics\\nmath: Good for answering math questions\\nHistory: Good for answering history questions\\ncomputer science: Good for answering computer science questions'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destinations_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b09c35c-83a3-456b-8232-4c98b923d2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"\"\"You must reply in Korean.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "563f0ef9-e0bc-4684-9b2a-a7f997cdb991",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d590bd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f609e185-6c79-443b-bb55-a2ed625b4439",
   "metadata": {},
   "source": [
    "## 프롬프트 번역\n",
    "```\n",
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"원시 텍스트 입력이 주어지면 \\\n",
    "언어 모델에 원시 텍스트 입력이 주어지면 입력에 가장 적합한 모델 프롬프트를 선택합니다. \\\n",
    "사용 가능한 프롬프트의 이름과 가장 적합한 프롬프트가 무엇인지에 대한 \\\"\n",
    "프롬프트의 이름과 해당 프롬프트가 가장 적합한 항목에 대한 설명이 제공됩니다. \\\n",
    "원래 입력을 수정하는 것이 궁극적으로 더 나은 응답으로 이어질 것이라고 생각되면 \\원래 입력을 수정할 수도 있습니다.\n",
    "수정하는 것이 궁극적으로 언어 모델에서 더 나은 응답을 얻을 수 있다고 생각되면 수정할 수도 있습니다.\n",
    "\n",
    "<< FORMATTING >>\n",
    "다음과 같은 형식의 JSON 객체가 포함된 마크다운 코드 스니펫을 반환합니다:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ 사용할 프롬프트의 이름 또는 \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ 원본 입력의 잠재적으로 수정된 버전\n",
    "}}}}\n",
    "```\n",
    "\n",
    "참고: \"대상\"은 아래에 지정된 후보 프롬프트 \\\n",
    "아래에 지정된 이름 중 하나이거나, 입력이 후보 프롬프트 중 하나에 \\\"적합하지 않은 경우 \\\"DEFAULT\" 일 수 있습니다.\n",
    "후보 프롬프트 중 하나에 적합하지 않은 경우 \"DEFAULT\"일 수 있습니다.\n",
    "기억하세요: \"next_inputs\"는 원래 입력일 수도 있습니다.\n",
    "그대로 사용할 수 있습니다.\n",
    "\n",
    "<< 후보 프롬프트 >>\n",
    "{대상}\n",
    "\n",
    "<< 입력 >>\n",
    "{입력}}\n",
    "\n",
    "<< OUTPUT (```json)>>\"\"\"을 포함해야 함을 잊지 마세요.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "147763e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ed6707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b0fcbdb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': 'What is black body radiation?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'블랙 바디 방사선은 모든 물질이 가지고 있는 열 에너지를 방출하는 현상입니다. 이러한 방출은 모든 온도에서 나타날 수 있으며, 저온에서는 주로 장파 길이의 빛을 방출하고, 고온에서는 짧은 파장의 방사선을 방출합니다. 이 방사선은 공간에서 양자화되며, 플랑크 법칙에 따라 각 파장에서의 방출 에너지는 온도와 밀접히 관련되어 있습니다. 블랙 바디 방사선은 우리가 일상에서 볼 수 있는 대부분의 사물에서 발생하며, 천문학, 열역학, 양자역학 등 많은 물리학 분야에서 중요한 개념입니다.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What is black body radiation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "328803a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "math: {'input': \"what is Fermat's Last Theorem\"}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"페르마의 마지막 정리(Fermat's Last Theorem)는 약 350년 동안 풀리지 않았던 유명한 수학 문제입니다. 이 문제는 피오네 방정식(x^n + y^n = z^n)의 정수해가 존재하지 않는다는 내용을 담고 있습니다. 다시 말해, 양의 정수 x, y, z와 양의 정수 n에 대해, x^n + y^n = z^n을 만족하는 경우는 존재하지 않습니다. 이 문제는 피오네 방정식을 만족하는 정수해가 발견되지 않아 페르마(Fermat)가 자신의 주장을 증명하지 못하고 남겨진 것으로 알려져 있습니다. 그러나 1994년에 앤드루 와일즈(Andrew Wiles)가 페르마의 마지막 정리를 증명하여 오랜 기간 동안의 수학적 난제를 해결했습니다. 와일즈의 증명은 높은 수학적 난이도를 가지고 있으며, 많은 수학자들에게 큰 영감을 주었습니다.\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"what is Fermat's Last Theorem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4d5fe8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "None: {'input': 'Why does every cell in our body contain DNA?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'모든 세포가 DNA를 포함하는 이유는 무엇인가요?'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Why does every cell in our body contain DNA?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "28e4793b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "None: {'input': 'how to make kimchi'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'김치를 만드는 방법은 다음과 같습니다:\\n\\n1. 배추를 준비합니다.\\n2. 배추를 깨끗이 씻은 후 소금물에 담갔다가 2-3시간 동안 절여둡니다.\\n3. 절인 배추를 깨끗하게 헹굽니다.\\n4. 배추 외에도 무, 파, 마늘, 생강, 고추가루 등을 잘게 다져 준비합니다.\\n5. 다진 재료에 고춧가루를 넣고 비벼주면, 김치 양념장이 완성됩니다.\\n6. 배추 한 장씩을 양념장에 꼭 묻힌 후 김치용기에 담아줍니다.\\n7. 김치용기에 배추를 계속 담아서 쌓아주고, 마지막에 양념장을 가장자리에 발라줍니다.\\n8. 담근 김치를 상온에서 2-3일 동안 숙성시킨 후 냉장고에 보관하면 완성됩니다.\\n\\n이렇게 하면 집에서 맛있는 김치를 만들 수 있습니다. 맛과 양념의 조절은 개인의 취향에 따라 조금씩 다를 수 있으니, 원하는 맛을 위해 양념의 양을 조절해보세요. 즐거운 김치 만들기 되시기 바랍니다!'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"how to make kimchi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afc48ea-0d40-4f8e-9946-ea0645bf86d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
