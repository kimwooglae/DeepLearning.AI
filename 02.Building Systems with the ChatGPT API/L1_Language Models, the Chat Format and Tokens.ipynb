{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56c8977d",
   "metadata": {},
   "source": [
    "# L1 언어 모델, 채팅 형식 및 토큰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c24f6d9",
   "metadata": {},
   "source": [
    "## 설정 \n",
    "### API 키와 관련 Python 라이브러리를 로드합니다. \n",
    "이 과정에서는 OpenAI API 키를 로드하는 몇 가지 코드를 제공했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83c7fa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57e63b0",
   "metadata": {},
   "source": [
    "#### 도우미 기능\n",
    "전 과정인 \"개발자를 위한 ChatGPT 프롬프트 엔지니어링\" 과정을 수강했다면 익숙하게 보일 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3d7bf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e873d68",
   "metadata": {},
   "source": [
    "## 모델에게 메시지를 표시하고 완료를 유도합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28ae61c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_completion(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eb0b783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75101797",
   "metadata": {},
   "source": [
    "## 토큰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bef46255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reversed letters of \"lollipop\" are \"pillipol\".\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(\"Take the letters in lollipop \\\n",
    "and reverse them\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60051cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_completion(\"\"\"Take the letters in \\\n",
    "l-o-l-l-i-p-o-p and reverse them\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae6bdb65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p-o-p-i-l-l-o-l'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651282fe",
   "metadata": {},
   "source": [
    "## 헬퍼 기능(채팅 형식) \n",
    "이 강좌에서 사용할 헬퍼 기능은 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7495592d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_from_messages(messages, \n",
    "                                 model=\"gpt-3.5-turbo\", \n",
    "                                 temperature=0, \n",
    "                                 max_tokens=500):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "        max_tokens=max_tokens, # the maximum number of tokens the model can ouptut \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49594ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, there was a happy carrot, so bright and so bold,\n",
      "With leaves so green and a story to be told.\n",
      "Firmly rooted in the earth, its happiness grew,\n",
      "As it soaked up the sunshine and the morning dew.\n",
      "\n",
      "From tiny seed to growing sprout,\n",
      "The carrot danced and laughed about.\n",
      "Its orange body swayed with glee,\n",
      "A happy, jolly carrot, you will see!\n",
      "\n",
      "With every bite, its sweetness gave gladness,\n",
      "Oh, this happy carrot brought such happiness.\n",
      "So munch away, my dear friend,\n",
      "On this joyful carrot, that'll never end!\n",
      "\n",
      "For in its juicy crunch, love it surely imparts,\n",
      "A happy carrot, straight from the heart.\n",
      "So grab it, enjoy it, and don't forget to share,\n",
      "This happy carrot's joy, everywhere!\n"
     ]
    }
   ],
   "source": [
    "messages =  [  \n",
    "{'role':'system', \n",
    " 'content':\"\"\"You are an assistant who\\\n",
    " responds in the style of Dr Seuss.\"\"\"},    \n",
    "{'role':'user', \n",
    " 'content':\"\"\"write me a very short poem\\\n",
    " about a happy carrot\"\"\"},  \n",
    "] \n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6eee8790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a carrot named Charlie who lived in a beautiful garden and always had a smile on his face.\n"
     ]
    }
   ],
   "source": [
    "# length\n",
    "messages =  [  \n",
    "{'role':'system',\n",
    " 'content':'All your responses must be \\\n",
    "one sentence long.'},    \n",
    "{'role':'user',\n",
    " 'content':'write me a story about a happy carrot'},  \n",
    "] \n",
    "response = get_completion_from_messages(messages, temperature =1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4922002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once there was a carrot named Larry, who was so full of joy it made everyone merry.\n"
     ]
    }
   ],
   "source": [
    "# combined\n",
    "messages =  [  \n",
    "{'role':'system',\n",
    " 'content':\"\"\"You are an assistant who \\\n",
    "responds in the style of Dr Seuss. \\\n",
    "All your responses must be one sentence long.\"\"\"},    \n",
    "{'role':'user',\n",
    " 'content':\"\"\"write me a story about a happy carrot\"\"\"},\n",
    "] \n",
    "response = get_completion_from_messages(messages, \n",
    "                                        temperature =1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22dfc799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_and_token_count(messages, \n",
    "                                   model=\"gpt-3.5-turbo\", \n",
    "                                   temperature=0, \n",
    "                                   max_tokens=500):\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, \n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    \n",
    "    content = response.choices[0].message[\"content\"]\n",
    "    \n",
    "    token_dict = {\n",
    "'prompt_tokens':response['usage']['prompt_tokens'],\n",
    "'completion_tokens':response['usage']['completion_tokens'],\n",
    "'total_tokens':response['usage']['total_tokens'],\n",
    "    }\n",
    "\n",
    "    return content, token_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e7687ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "{'role':'system', \n",
    " 'content':\"\"\"You are an assistant who responds\\\n",
    " in the style of Dr Seuss.\"\"\"},    \n",
    "{'role':'user',\n",
    " 'content':\"\"\"write me a very short poem \\ \n",
    " about a happy carrot\"\"\"},  \n",
    "] \n",
    "response, token_dict = get_completion_and_token_count(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a45ef5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a garden so bright, with colors so cheery,\n",
      "There lived a carrot, oh so merry!\n",
      "With a vibrant orange hue, and a leafy green top,\n",
      "This happy carrot just couldn't stop.\n",
      "\n",
      "It danced in the breeze, with a joyful sway,\n",
      "Spreading happiness throughout the day.\n",
      "With a smile so wide, and eyes full of glee,\n",
      "This carrot was as happy as can be.\n",
      "\n",
      "It loved the sunshine, and the rain's gentle touch,\n",
      "Growing tall and strong, oh so much!\n",
      "From the earth it sprouted, reaching for the sky,\n",
      "A happy carrot, oh my, oh my!\n",
      "\n",
      "So if you're feeling down, just remember this tale,\n",
      "Of a carrot so happy, it'll never fail.\n",
      "Find joy in the little things, and let your heart sing,\n",
      "Just like that carrot, oh what joy it will bring!\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "920c4627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt_tokens': 37, 'completion_tokens': 173, 'total_tokens': 210}\n"
     ]
    }
   ],
   "source": [
    "print(token_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fc588a",
   "metadata": {},
   "source": [
    "#### 이 강의실 외부에서 OpenAI API를 사용할 때 참고 사항\n",
    "\n",
    "OpenAI 파이썬 라이브러리를 설치하려면: \n",
    "``` \n",
    "!pip install openai \n",
    "```\n",
    "\n",
    "라이브러리는 [웹사이트](https://platform.openai.com/account/api-keys)에서 확인할 수 있는 계정의 비밀 키로 구성해야 합니다.\n",
    "\n",
    "라이브러리를 사용하기 전에 ` !export OPENAI_API_KEY='sk-...' ` 환경 변수로 설정할 수 있습니다.\n",
    "\n",
    "또는 `openai.api_key`를 해당 값으로 설정합니다:\n",
    "\n",
    "``` \n",
    "import openai openai.api_key = \"sk-...\" \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eca293",
   "metadata": {},
   "source": [
    "#### 백슬래시에 대한 참고 사항 \n",
    "- 이 강좌에서는 백슬래시 `\\`를 사용하여 개행 '\\n' 문자를 삽입하지 않고도 텍스트가 화면에 맞도록 하고 있습니다. \n",
    "- 개행 문자 삽입 여부에 관계없이 GPT-3는 실제로 영향을 받지 않습니다. 그러나 일반적으로 LLM으로 작업할 때는 프롬프트의 개행 문자가 모델의 성능에 영향을 미칠 수 있는지 고려할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6da0bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
